<div class="td-content"><h1 data-pagefind-weight="10">Pod Lifecycle</h1><p>This page describes the lifecycle of a Pod. Pods follow a defined lifecycle, starting
in the <code>Pending</code> <a href="#pod-phase">phase</a>, moving through <code>Running</code> if at least one
of its primary containers starts OK, and then through either the <code>Succeeded</code> or
<code>Failed</code> phases depending on whether any container in the Pod terminated in failure.</p><p>Like individual application containers, Pods are considered to be relatively
ephemeral (rather than durable) entities. Pods are created, assigned a unique
ID (<a href="/docs/concepts/overview/working-with-objects/names/#uids">UID</a>), and scheduled
to run on nodes where they remain until termination (according to restart policy) or
deletion.
If a <a class="glossary-tooltip" title="A node is a worker machine in Kubernetes." data-toggle="tooltip" data-placement="top" href="/docs/concepts/architecture/nodes/" target="_blank" aria-label="Node">Node</a> dies, the Pods running on (or scheduled
to run on) that node are <a href="#pod-garbage-collection">marked for deletion</a>. The control
plane marks the Pods for removal after a timeout period.</p><h2 id="pod-lifetime">Pod lifetime</h2><p>Whilst a Pod is running, the kubelet is able to restart containers to handle some
kind of faults. Within a Pod, Kubernetes tracks different container
<a href="#container-states">states</a> and determines what action to take to make the Pod
healthy again.</p><p>In the Kubernetes API, Pods have both a specification and an actual status. The
status for a Pod object consists of a set of <a href="#pod-conditions">Pod conditions</a>.
You can also inject <a href="#pod-readiness-gate">custom readiness information</a> into the
condition data for a Pod, if that is useful to your application.</p><p>Pods are only <a href="/docs/concepts/scheduling-eviction/">scheduled</a> once in their lifetime;
assigning a Pod to a specific node is called <em>binding</em>, and the process of selecting
which node to use is called <em>scheduling</em>.
Once a Pod has been scheduled and is bound to a node, Kubernetes tries
to run that Pod on the node. The Pod runs on that node until it stops, or until the Pod
is <a href="#pod-termination">terminated</a>; if Kubernetes isn't able to start the Pod on the selected
node (for example, if the node crashes before the Pod starts), then that particular Pod
never starts.</p><p>You can use <a href="/docs/concepts/scheduling-eviction/pod-scheduling-readiness/">Pod Scheduling Readiness</a>
to delay scheduling for a Pod until all its <em>scheduling gates</em> are removed. For example,
you might want to define a set of Pods but only trigger scheduling once all the Pods
have been created.</p><h3 id="pod-fault-recovery">Pods and fault recovery</h3><p>If one of the containers in the Pod fails, then Kubernetes may try to restart that
specific container.
Read <a href="#container-restarts">How Pods handle problems with containers</a> to learn more.</p><p>Pods can however fail in a way that the cluster cannot recover from, and in that case
Kubernetes does not attempt to heal the Pod further; instead, Kubernetes deletes the
Pod and relies on other components to provide automatic healing.</p><p>If a Pod is scheduled to a <a class="glossary-tooltip" title="A node is a worker machine in Kubernetes." data-toggle="tooltip" data-placement="top" href="/docs/concepts/architecture/nodes/" target="_blank" aria-label="node">node</a> and that
node then fails, the Pod is treated as unhealthy and Kubernetes eventually deletes the Pod.
A Pod won't survive an <a class="glossary-tooltip" title="Process of terminating one or more Pods on Nodes" data-toggle="tooltip" data-placement="top" href="/docs/concepts/scheduling-eviction/" target="_blank" aria-label="eviction">eviction</a> due to
a lack of resources or Node maintenance.</p><p>Kubernetes uses a higher-level abstraction, called a
<a class="glossary-tooltip" title="A control loop that watches the shared state of the cluster through the apiserver and makes changes attempting to move the current state towards the desired state." data-toggle="tooltip" data-placement="top" href="/docs/concepts/architecture/controller/" target="_blank" aria-label="controller">controller</a>, that handles the work of
managing the relatively disposable Pod instances.</p><p>A given Pod (as defined by a UID) is never "rescheduled" to a different node; instead,
that Pod can be replaced by a new, near-identical Pod. If you make a replacement Pod, it can
even have same name (as in <code>.metadata.name</code>) that the old Pod had, but the replacement
would have a different <code>.metadata.uid</code> from the old Pod.</p><p>Kubernetes does not guarantee that a replacement for an existing Pod would be scheduled to
the same node as the old Pod that was being replaced.</p><h3 id="associated-lifetimes">Associated lifetimes</h3><p>When something is said to have the same lifetime as a Pod, such as a
<a class="glossary-tooltip" title="A directory containing data, accessible to the containers in a pod." data-toggle="tooltip" data-placement="top" href="/docs/concepts/storage/volumes/" target="_blank" aria-label="volume">volume</a>,
that means that the thing exists as long as that specific Pod (with that exact UID)
exists. If that Pod is deleted for any reason, and even if an identical replacement
is created, the related thing (a volume, in this example) is also destroyed and
created anew.</p><figure class="diagram-medium"><img src="/images/docs/pod.svg" alt="A multi-container Pod that contains a file puller sidecar and a web server. The Pod uses an ephemeral emptyDir volume for shared storage between the containers."/><figcaption><h4>Figure 1.</h4><p>A multi-container Pod that contains a file puller <a href="/docs/concepts/workloads/pods/sidecar-containers/">sidecar</a> and a web server. The Pod uses an <a href="/docs/concepts/storage/volumes/#emptydir">ephemeral <code>emptyDir</code> volume</a> for shared storage between the containers.</p></figcaption></figure><h2 id="pod-phase">Pod phase</h2><p>A Pod's <code>status</code> field is a
<a href="/docs/reference/generated/kubernetes-api/v1.34/#podstatus-v1-core">PodStatus</a>
object, which has a <code>phase</code> field.</p><p>The phase of a Pod is a simple, high-level summary of where the Pod is in its
lifecycle. The phase is not intended to be a comprehensive rollup of observations
of container or Pod state, nor is it intended to be a comprehensive state machine.</p><p>The number and meanings of Pod phase values are tightly guarded.
Other than what is documented here, nothing should be assumed about Pods that
have a given <code>phase</code> value.</p><p>Here are the possible values for <code>phase</code>:</p><table><thead><tr><th style="text-align:left">Value</th><th style="text-align:left">Description</th></tr></thead><tbody><tr><td style="text-align:left"><code>Pending</code></td><td style="text-align:left">The Pod has been accepted by the Kubernetes cluster, but one or more of the containers has not been set up and made ready to run. This includes time a Pod spends waiting to be scheduled as well as the time spent downloading container images over the network.</td></tr><tr><td style="text-align:left"><code>Running</code></td><td style="text-align:left">The Pod has been bound to a node, and all of the containers have been created. At least one container is still running, or is in the process of starting or restarting.</td></tr><tr><td style="text-align:left"><code>Succeeded</code></td><td style="text-align:left">All containers in the Pod have terminated in success, and will not be restarted.</td></tr><tr><td style="text-align:left"><code>Failed</code></td><td style="text-align:left">All containers in the Pod have terminated, and at least one container has terminated in failure. That is, the container either exited with non-zero status or was terminated by the system, and is not set for automatic restarting.</td></tr><tr><td style="text-align:left"><code>Unknown</code></td><td style="text-align:left">For some reason the state of the Pod could not be obtained. This phase typically occurs due to an error in communicating with the node where the Pod should be running.</td></tr></tbody></table><div class="alert alert-info" role="alert"><h4 class="alert-heading">Note:</h4><p>When a pod is failing to start repeatedly, <code>CrashLoopBackOff</code> may appear in the <code>Status</code> field of some kubectl commands.
Similarly, when a pod is being deleted, <code>Terminating</code> may appear in the <code>Status</code> field of some kubectl commands.</p><p>Make sure not to confuse <em>Status</em>, a kubectl display field for user intuition, with the pod's <code>phase</code>.
Pod phase is an explicit part of the Kubernetes data model and of the
<a href="/docs/reference/kubernetes-api/workload-resources/pod-v1/">Pod API</a>.</p><pre tabindex="0"><code>  NAMESPACE               NAME               READY   STATUS             RESTARTS   AGE
  alessandras-namespace   alessandras-pod    0/1     CrashLoopBackOff   200        2d9h
</code></pre><hr/><p>A Pod is granted a term to terminate gracefully, which defaults to 30 seconds.
You can use the flag <code>--force</code> to <a href="/docs/concepts/workloads/pods/pod-lifecycle/#pod-termination-forced">terminate a Pod by force</a>.</p></div><p>Since Kubernetes 1.27, the kubelet transitions deleted Pods, except for
<a href="/docs/tasks/configure-pod-container/static-pod/">static Pods</a> and
<a href="/docs/concepts/workloads/pods/pod-lifecycle/#pod-termination-forced">force-deleted Pods</a>
without a finalizer, to a terminal phase (<code>Failed</code> or <code>Succeeded</code> depending on
the exit statuses of the pod containers) before their deletion from the API server.</p><p>If a node dies or is disconnected from the rest of the cluster, Kubernetes
applies a policy for setting the <code>phase</code> of all Pods on the lost node to Failed.</p><h2 id="container-states">Container states</h2><p>As well as the <a href="#pod-phase">phase</a> of the Pod overall, Kubernetes tracks the state of
each container inside a Pod. You can use
<a href="/docs/concepts/containers/container-lifecycle-hooks/">container lifecycle hooks</a> to
trigger events to run at certain points in a container's lifecycle.</p><p>Once the <a class="glossary-tooltip" title="Control plane component that watches for newly created pods with no assigned node, and selects a node for them to run on." data-toggle="tooltip" data-placement="top" href="/docs/reference/command-line-tools-reference/kube-scheduler/" target="_blank" aria-label="scheduler">scheduler</a>
assigns a Pod to a Node, the kubelet starts creating containers for that Pod
using a <a class="glossary-tooltip" title="The container runtime is the software that is responsible for running containers." data-toggle="tooltip" data-placement="top" href="/docs/setup/production-environment/container-runtimes" target="_blank" aria-label="container runtime">container runtime</a>.
There are three possible container states: <code>Waiting</code>, <code>Running</code>, and <code>Terminated</code>.</p><p>To check the state of a Pod's containers, you can use
<code>kubectl describe pod &lt;name-of-pod&gt;</code>. The output shows the state for each container
within that Pod.</p><p>Each state has a specific meaning:</p><h3 id="container-state-waiting"><code>Waiting</code></h3><p>If a container is not in either the <code>Running</code> or <code>Terminated</code> state, it is <code>Waiting</code>.
A container in the <code>Waiting</code> state is still running the operations it requires in
order to complete start up: for example, pulling the container image from a container
image registry, or applying <a class="glossary-tooltip" title="Stores sensitive information, such as passwords, OAuth tokens, and ssh keys." data-toggle="tooltip" data-placement="top" href="/docs/concepts/configuration/secret/" target="_blank" aria-label="Secret">Secret</a>
data.
When you use <code>kubectl</code> to query a Pod with a container that is <code>Waiting</code>, you also see
a Reason field to summarize why the container is in that state.</p><h3 id="container-state-running"><code>Running</code></h3><p>The <code>Running</code> status indicates that a container is executing without issues. If there
was a <code>postStart</code> hook configured, it has already executed and finished. When you use
<code>kubectl</code> to query a Pod with a container that is <code>Running</code>, you also see information
about when the container entered the <code>Running</code> state.</p><h3 id="container-state-terminated"><code>Terminated</code></h3><p>A container in the <code>Terminated</code> state began execution and then either ran to
completion or failed for some reason. When you use <code>kubectl</code> to query a Pod with
a container that is <code>Terminated</code>, you see a reason, an exit code, and the start and
finish time for that container's period of execution.</p><p>If a container has a <code>preStop</code> hook configured, this hook runs before the container enters
the <code>Terminated</code> state.</p><h2 id="container-restarts">How Pods handle problems with containers</h2><p>Kubernetes manages container failures within Pods using a <a href="#restart-policy"><code>restartPolicy</code></a> defined in the Pod <code>spec</code>. This policy determines how Kubernetes reacts to containers exiting due to errors or other reasons, which falls in the following sequence:</p><ol><li><strong>Initial crash</strong>: Kubernetes attempts an immediate restart based on the Pod <code>restartPolicy</code>.</li><li><strong>Repeated crashes</strong>: After the initial crash Kubernetes applies an exponential
backoff delay for subsequent restarts, described in <a href="#restart-policy"><code>restartPolicy</code></a>.
This prevents rapid, repeated restart attempts from overloading the system.</li><li><strong>CrashLoopBackOff state</strong>: This indicates that the backoff delay mechanism is currently
in effect for a given container that is in a crash loop, failing and restarting repeatedly.</li><li><strong>Backoff reset</strong>: If a container runs successfully for a certain duration
(e.g., 10 minutes), Kubernetes resets the backoff delay, treating any new crash
as the first one.</li></ol><p>In practice, a <code>CrashLoopBackOff</code> is a condition or event that might be seen as output
from the <code>kubectl</code> command, while describing or listing Pods, when a container in the Pod
fails to start properly and then continually tries and fails in a loop.</p><p>In other words, when a container enters the crash loop, Kubernetes applies the
exponential backoff delay mentioned in the <a href="#restart-policy">Container restart policy</a>.
This mechanism prevents a faulty container from overwhelming the system with continuous
failed start attempts.</p><p>The <code>CrashLoopBackOff</code> can be caused by issues like the following:</p><ul><li>Application errors that cause the container to exit.</li><li>Configuration errors, such as incorrect environment variables or missing
configuration files.</li><li>Resource constraints, where the container might not have enough memory or CPU
to start properly.</li><li>Health checks failing if the application doesn't start serving within the
expected time.</li><li>Container liveness probes or startup probes returning a <code>Failure</code> result
as mentioned in the <a href="#container-probes">probes section</a>.</li></ul><p>To investigate the root cause of a <code>CrashLoopBackOff</code> issue, a user can:</p><ol><li><strong>Check logs</strong>: Use <code>kubectl logs &lt;name-of-pod&gt;</code> to check the logs of the container.
This is often the most direct way to diagnose the issue causing the crashes.</li><li><strong>Inspect events</strong>: Use <code>kubectl describe pod &lt;name-of-pod&gt;</code> to see events
for the Pod, which can provide hints about configuration or resource issues.</li><li><strong>Review configuration</strong>: Ensure that the Pod configuration, including
environment variables and mounted volumes, is correct and that all required
external resources are available.</li><li><strong>Check resource limits</strong>: Make sure that the container has enough CPU
and memory allocated. Sometimes, increasing the resources in the Pod definition
can resolve the issue.</li><li><strong>Debug application</strong>: There might exist bugs or misconfigurations in the
application code. Running this container image locally or in a development
environment can help diagnose application specific issues.</li></ol><h3 id="restart-policy">Container restarts</h3><p>When a container in your Pod stops, or experiences failure, Kubernetes can restart it.
A restart isn't always appropriate; for example,
<a class="glossary-tooltip" title="One or more initialization containers that must run to completion before any app containers run." data-toggle="tooltip" data-placement="top" href="/docs/concepts/workloads/pods/init-containers/" target="_blank" aria-label="init containers">init containers</a> run only once,
during Pod startup.</p><p>You can configure restarts as a policy that applies to all Pods, or using container-level configuration (for example: when you define a
<a class="glossary-tooltip" title="An auxilliary container that stays running throughout the lifecycle of a Pod." data-toggle="tooltip" data-placement="top" href="/docs/concepts/workloads/pods/sidecar-containers/" target="_blank" aria-label="sidecar container">sidecar container</a>).</p><h4 id="container-restart-resilience">Container restarts and resilience</h4><p>The Kubernetes project recommends following cloud-native principles, including resilient
design that accounts for unannounced or arbitrary restarts. You can achieve this either
by failing the Pod and relying on automatic
<a href="/docs/concepts/workloads/controllers/">replacement</a>, or you can design for container-level resilience.
Either approach helps to ensure that your overall workload remains available despite
partial failure.</p><h4 id="pod-level-container-restart-policy">Pod-level container restart policy</h4><p>The <code>spec</code> of a Pod has a <code>restartPolicy</code> field with possible values Always, OnFailure,
and Never. The default value is Always.</p><p>The <code>restartPolicy</code> for a Pod applies to <a class="glossary-tooltip" title="A container used to run part of a workload. Compare with init container." data-toggle="tooltip" data-placement="top" href="/docs/reference/glossary/?all=true#term-app-container" target="_blank" aria-label="app containers">app containers</a>
in the Pod and to regular <a href="/docs/concepts/workloads/pods/init-containers/">init containers</a>.
<a href="/docs/concepts/workloads/pods/sidecar-containers/">Sidecar containers</a>
ignore the Pod-level <code>restartPolicy</code> field: in Kubernetes, a sidecar is defined as an
entry inside <code>initContainers</code> that has its container-level <code>restartPolicy</code> set to <code>Always</code>.
For init containers that exit with an error, the kubelet restarts the init container if
the Pod level <code>restartPolicy</code> is either <code>OnFailure</code> or <code>Always</code>:</p><ul><li><code>Always</code>: Automatically restarts the container after any termination.</li><li><code>OnFailure</code>: Only restarts the container if it exits with an error (non-zero exit status).</li><li><code>Never</code>: Does not automatically restart the terminated container.</li></ul><p>When the kubelet is handling container restarts according to the configured restart
policy, that only applies to restarts that make replacement containers inside the
same Pod and running on the same node. After containers in a Pod exit, the kubelet
restarts them with an exponential backoff delay (10s, 20s, 40s, …), that is capped at
300 seconds (5 minutes). Once a container has executed for 10 minutes without any
problems, the kubelet resets the restart backoff timer for that container.
<a href="/docs/concepts/workloads/pods/sidecar-containers/#sidecar-containers-and-pod-lifecycle">Sidecar containers and Pod lifecycle</a>
explains the behaviour of <code>init containers</code> when specify <code>restartpolicy</code> field on it.</p><h4 id="container-restart-rules">Individual container restart policy and rules</h4><div class="feature-state-notice feature-alpha" title="Feature Gate: ContainerRestartRules"><span class="feature-state-name">FEATURE STATE:</span>
<code>Kubernetes v1.34 [alpha]</code> (enabled by default: false)</div><p>If your cluster has the feature gate <code>ContainerRestartRules</code> enabled, you can specify
<code>restartPolicy</code> and <code>restartPolicyRules</code> on <em>individual containers</em> to override the Pod
restart policy. Container restart policy and rules applies to <a class="glossary-tooltip" title="A container used to run part of a workload. Compare with init container." data-toggle="tooltip" data-placement="top" href="/docs/reference/glossary/?all=true#term-app-container" target="_blank" aria-label="app containers">app containers</a>
in the Pod and to regular <a href="/docs/concepts/workloads/pods/init-containers/">init containers</a>.</p><p>A Kubernetes-native <a href="/docs/concepts/workloads/pods/sidecar-containers/">sidecar container</a>
has its container-level <code>restartPolicy</code> set to <code>Always</code>, and does not support <code>restartPolicyRules</code>.</p><p>The container restarts will follow the same exponential backoff as pod restart policy described above.
Supported container restart policies:</p><ul><li><code>Always</code>: Automatically restarts the container after any termination.</li><li><code>OnFailure</code>: Only restarts the container if it exits with an error (non-zero exit status).</li><li><code>Never</code>: Does not automatically restart the terminated container.</li></ul><p>Additionally, <em>individual containers</em> can specify <code>restartPolicyRules</code>. If the <code>restartPolicyRules</code>
field is specified, then container <code>restartPolicy</code> <strong>must</strong> also be specified. The <code>restartPolicyRules</code>
define a list of rules to apply on container exit. Each rule will consist of a condition
and an action. The supported condition is <code>exitCodes</code>, which compares the exit code of the container
with a list of given values. The supported action is <code>Restart</code>, which means the container will be
restarted. The rules will be evaluated in order. On the first match, the action will be applied.
If none of the rules’ conditions matched, Kubernetes fallback to container’s configured
<code>restartPolicy</code>.</p><p>For example, a Pod with OnFailure restart policy that have a <code>try-once</code> container. This allows
Pod to only restart certain containers:</p><div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="display:flex"><span><span style="color:green;font-weight:700">apiVersion</span>:<span style="color:#bbb"> </span>v1<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb"/><span style="color:green;font-weight:700">kind</span>:<span style="color:#bbb"> </span>Pod<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb"/><span style="color:green;font-weight:700">metadata</span>:<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">  </span><span style="color:green;font-weight:700">name</span>:<span style="color:#bbb"> </span><span style="color:#a2f;font-weight:700">on</span>-failure-pod<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb"/><span style="color:green;font-weight:700">spec</span>:<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">  </span><span style="color:green;font-weight:700">restartPolicy</span>:<span style="color:#bbb"> </span>OnFailure<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">  </span><span style="color:green;font-weight:700">containers</span>:<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">  </span>- <span style="color:green;font-weight:700">name</span>:<span style="color:#bbb"> </span>try-once-container   <span style="color:#bbb"> </span><span style="color:#080;font-style:italic"># This container will run only once because the restartPolicy is Never.</span><span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">    </span><span style="color:green;font-weight:700">image</span>:<span style="color:#bbb"> </span>docker.io/library/busybox:1.28<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">    </span><span style="color:green;font-weight:700">command</span>:<span style="color:#bbb"> </span>[<span style="color:#b44">'sh'</span>,<span style="color:#bbb"> </span><span style="color:#b44">'-c'</span>,<span style="color:#bbb"> </span><span style="color:#b44">'echo "Only running once" &amp;&amp; sleep 10 &amp;&amp; exit 1'</span>]<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">    </span><span style="color:green;font-weight:700">restartPolicy</span>:<span style="color:#bbb"> </span>Never     <span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">  </span>- <span style="color:green;font-weight:700">name</span>:<span style="color:#bbb"> </span><span style="color:#a2f;font-weight:700">on</span>-failure-container <span style="color:#bbb"> </span><span style="color:#080;font-style:italic"># This container will be restarted on failure.</span><span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">    </span><span style="color:green;font-weight:700">image</span>:<span style="color:#bbb"> </span>docker.io/library/busybox:1.28<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">    </span><span style="color:green;font-weight:700">command</span>:<span style="color:#bbb"> </span>[<span style="color:#b44">'sh'</span>,<span style="color:#bbb"> </span><span style="color:#b44">'-c'</span>,<span style="color:#bbb"> </span><span style="color:#b44">'echo "Keep restarting" &amp;&amp; sleep 1800 &amp;&amp; exit 1'</span>]<span style="color:#bbb">
</span></span></span></code></pre></div><p>A Pod with Always restart policy with an init container that only execute once. If the init
container fails, the Pod fails. This allows the Pod to fail if the initialization failed,
but also keep running once the initialization succeeds:</p><div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="display:flex"><span><span style="color:green;font-weight:700">apiVersion</span>:<span style="color:#bbb"> </span>v1<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb"/><span style="color:green;font-weight:700">kind</span>:<span style="color:#bbb"> </span>Pod<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb"/><span style="color:green;font-weight:700">metadata</span>:<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">  </span><span style="color:green;font-weight:700">name</span>:<span style="color:#bbb"> </span>fail-pod-if-init-fails<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb"/><span style="color:green;font-weight:700">spec</span>:<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">  </span><span style="color:green;font-weight:700">restartPolicy</span>:<span style="color:#bbb"> </span>Always<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">  </span><span style="color:green;font-weight:700">initContainers</span>:<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">  </span>- <span style="color:green;font-weight:700">name</span>:<span style="color:#bbb"> </span>init-once     <span style="color:#bbb"> </span><span style="color:#080;font-style:italic"># This init container will only try once. If it fails, the pod will fail.</span><span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">    </span><span style="color:green;font-weight:700">image</span>:<span style="color:#bbb"> </span>docker.io/library/busybox:1.28<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">    </span><span style="color:green;font-weight:700">command</span>:<span style="color:#bbb"> </span>[<span style="color:#b44">'sh'</span>,<span style="color:#bbb"> </span><span style="color:#b44">'-c'</span>,<span style="color:#bbb"> </span><span style="color:#b44">'echo "Failing initialization" &amp;&amp; sleep 10 &amp;&amp; exit 1'</span>]<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">    </span><span style="color:green;font-weight:700">restartPolicy</span>:<span style="color:#bbb"> </span>Never<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">  </span><span style="color:green;font-weight:700">containers</span>:<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">  </span>- <span style="color:green;font-weight:700">name</span>:<span style="color:#bbb"> </span>main-container<span style="color:#bbb"> </span><span style="color:#080;font-style:italic"># This container will always be restarted once initialization succeeds.</span><span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">    </span><span style="color:green;font-weight:700">image</span>:<span style="color:#bbb"> </span>docker.io/library/busybox:1.28<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">    </span><span style="color:green;font-weight:700">command</span>:<span style="color:#bbb"> </span>[<span style="color:#b44">'sh'</span>,<span style="color:#bbb"> </span><span style="color:#b44">'-c'</span>,<span style="color:#bbb"> </span><span style="color:#b44">'sleep 1800 &amp;&amp; exit 0'</span>]<span style="color:#bbb">
</span></span></span></code></pre></div><p>A Pod with Never restart policy with a container that ignores and restarts on specific exit codes.
This is useful to differentiate between restartable errors and non-restartable errors:</p><div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="display:flex"><span><span style="color:green;font-weight:700">apiVersion</span>:<span style="color:#bbb"> </span>v1<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb"/><span style="color:green;font-weight:700">kind</span>:<span style="color:#bbb"> </span>Pod<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb"/><span style="color:green;font-weight:700">metadata</span>:<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">  </span><span style="color:green;font-weight:700">name</span>:<span style="color:#bbb"> </span>restart-on-exit-codes<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb"/><span style="color:green;font-weight:700">spec</span>:<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">  </span><span style="color:green;font-weight:700">restartPolicy</span>:<span style="color:#bbb"> </span>Never<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">  </span><span style="color:green;font-weight:700">containers</span>:<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">  </span>- <span style="color:green;font-weight:700">name</span>:<span style="color:#bbb"> </span>restart-on-exit-codes<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">    </span><span style="color:green;font-weight:700">image</span>:<span style="color:#bbb"> </span>docker.io/library/busybox:1.28<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">    </span><span style="color:green;font-weight:700">command</span>:<span style="color:#bbb"> </span>[<span style="color:#b44">'sh'</span>,<span style="color:#bbb"> </span><span style="color:#b44">'-c'</span>,<span style="color:#bbb"> </span><span style="color:#b44">'sleep 60 &amp;&amp; exit 0'</span>]<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">    </span><span style="color:green;font-weight:700">restartPolicy</span>:<span style="color:#bbb"> </span>Never    <span style="color:#bbb"> </span><span style="color:#080;font-style:italic"># Container restart policy must be specified if rules are specified</span><span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">    </span><span style="color:green;font-weight:700">restartPolicyRules</span>:<span style="color:#bbb">      </span><span style="color:#080;font-style:italic"># Only restart the container if it exits with code 42</span><span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">    </span>- <span style="color:green;font-weight:700">action</span>:<span style="color:#bbb"> </span>Restart<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">      </span><span style="color:green;font-weight:700">exitCodes</span>:<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">        </span><span style="color:green;font-weight:700">operator</span>:<span style="color:#bbb"> </span>In<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">        </span><span style="color:green;font-weight:700">values</span>:<span style="color:#bbb"> </span>[<span style="color:#666">42</span>]<span style="color:#bbb">
</span></span></span></code></pre></div><p>Restart rules can be used for many more advanced lifecycle management scenarios. Note, restart rules
are affected by the same inconsistencies as the regular restart policy. Kubelet restarts, container
runtime garbage collection, intermitted connectivity issues with the control plane may cause the state
loss and containers may be re-run even when you expect a container not to be restarted.</p><h3 id="reduced-container-restart-delay">Reduced container restart delay</h3><div class="feature-state-notice feature-alpha" title="Feature Gate: ReduceDefaultCrashLoopBackOffDecay"><span class="feature-state-name">FEATURE STATE:</span>
<code>Kubernetes v1.33 [alpha]</code> (enabled by default: false)</div><p>With the alpha feature gate <code>ReduceDefaultCrashLoopBackOffDecay</code> enabled,
container start retries across your cluster will be reduced to begin at 1s
(instead of 10s) and increase exponentially by 2x each restart until a maximum
delay of 60s (instead of 300s which is 5 minutes).</p><p>If you use this feature along with the alpha feature
<code>KubeletCrashLoopBackOffMax</code> (described below), individual nodes may have
different maximum delays.</p><h3 id="configurable-container-restart-delay">Configurable container restart delay</h3><div class="feature-state-notice feature-alpha" title="Feature Gate: KubeletCrashLoopBackOffMax"><span class="feature-state-name">FEATURE STATE:</span>
<code>Kubernetes v1.32 [alpha]</code> (enabled by default: false)</div><p>With the alpha feature gate <code>KubeletCrashLoopBackOffMax</code> enabled, you can
reconfigure the maximum delay between container start retries from the default
of 300s (5 minutes). This configuration is set per node using kubelet
configuration. In your <a href="/docs/tasks/administer-cluster/kubelet-config-file/">kubelet
configuration</a>, under
<code>crashLoopBackOff</code> set the <code>maxContainerRestartPeriod</code> field between <code>"1s"</code> and
<code>"300s"</code>. As described above in <a href="#restart-policy">Container restart policy</a>,
delays on that node will still start at 10s and increase exponentially by 2x
each restart, but will now be capped at your configured maximum. If the
<code>maxContainerRestartPeriod</code> you configure is less than the default initial value
of 10s, the initial delay will instead be set to the configured maximum.</p><p>See the following kubelet configuration examples:</p><div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="display:flex"><span><span style="color:#080;font-style:italic"># container restart delays will start at 10s, increasing</span><span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb"/><span style="color:#080;font-style:italic"># 2x each time they are restarted, to a maximum of 100s</span><span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb"/><span style="color:green;font-weight:700">kind</span>:<span style="color:#bbb"> </span>KubeletConfiguration<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb"/><span style="color:green;font-weight:700">crashLoopBackOff</span>:<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">    </span><span style="color:green;font-weight:700">maxContainerRestartPeriod</span>:<span style="color:#bbb"> </span><span style="color:#b44">"100s"</span><span style="color:#bbb">
</span></span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="display:flex"><span><span style="color:#080;font-style:italic"># delays between container restarts will always be 2s</span><span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb"/><span style="color:green;font-weight:700">kind</span>:<span style="color:#bbb"> </span>KubeletConfiguration<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb"/><span style="color:green;font-weight:700">crashLoopBackOff</span>:<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">    </span><span style="color:green;font-weight:700">maxContainerRestartPeriod</span>:<span style="color:#bbb"> </span><span style="color:#b44">"2s"</span><span style="color:#bbb">
</span></span></span></code></pre></div><p>If you use this feature along with the alpha feature
<code>ReduceDefaultCrashLoopBackOffDecay</code> (described above), your cluster defaults
for initial backoff and maximum backoff will no longer be 10s and 300s, but 1s
and 60s. Per node configuration takes precedence over the defaults set by
<code>ReduceDefaultCrashLoopBackOffDecay</code>, even if this would result in a node having
a longer maximum backoff than other nodes in the cluster.</p><h2 id="pod-conditions">Pod conditions</h2><p>A Pod has a PodStatus, which has an array of
<a href="/docs/reference/generated/kubernetes-api/v1.34/#podcondition-v1-core">PodConditions</a>
through which the Pod has or has not passed. Kubelet manages the following
PodConditions:</p><ul><li><code>PodScheduled</code>: the Pod has been scheduled to a node.</li><li><code>PodReadyToStartContainers</code>: (beta feature; enabled by <a href="#pod-has-network">default</a>) the
Pod sandbox has been successfully created and networking configured.</li><li><code>ContainersReady</code>: all containers in the Pod are ready.</li><li><code>Initialized</code>: all <a href="/docs/concepts/workloads/pods/init-containers/">init containers</a>
have completed successfully.</li><li><code>Ready</code>: the Pod is able to serve requests and should be added to the load
balancing pools of all matching Services.</li><li><code>DisruptionTarget</code>: the pod is about to be terminated due to a disruption (such as preemption, eviction or garbage-collection).</li><li><code>PodResizePending</code>: a pod resize was requested but cannot be applied. See <a href="/docs/tasks/configure-pod-container/resize-container-resources/#pod-resize-status">Pod resize status</a>.</li><li><code>PodResizeInProgress</code>: the pod is in the process of resizing. See <a href="/docs/tasks/configure-pod-container/resize-container-resources/#pod-resize-status">Pod resize status</a>.</li></ul><table><thead><tr><th style="text-align:left">Field name</th><th style="text-align:left">Description</th></tr></thead><tbody><tr><td style="text-align:left"><code>type</code></td><td style="text-align:left">Name of this Pod condition.</td></tr><tr><td style="text-align:left"><code>status</code></td><td style="text-align:left">Indicates whether that condition is applicable, with possible values "<code>True</code>", "<code>False</code>", or "<code>Unknown</code>".</td></tr><tr><td style="text-align:left"><code>lastProbeTime</code></td><td style="text-align:left">Timestamp of when the Pod condition was last probed.</td></tr><tr><td style="text-align:left"><code>lastTransitionTime</code></td><td style="text-align:left">Timestamp for when the Pod last transitioned from one status to another.</td></tr><tr><td style="text-align:left"><code>reason</code></td><td style="text-align:left">Machine-readable, UpperCamelCase text indicating the reason for the condition's last transition.</td></tr><tr><td style="text-align:left"><code>message</code></td><td style="text-align:left">Human-readable message indicating details about the last status transition.</td></tr></tbody></table><h3 id="pod-readiness-gate">Pod readiness</h3><div class="feature-state-notice feature-stable"><span class="feature-state-name">FEATURE STATE:</span>
<code>Kubernetes v1.14 [stable]</code></div><p>Your application can inject extra feedback or signals into PodStatus:
<em>Pod readiness</em>. To use this, set <code>readinessGates</code> in the Pod's <code>spec</code> to
specify a list of additional conditions that the kubelet evaluates for Pod readiness.</p><p>Readiness gates are determined by the current state of <code>status.condition</code>
fields for the Pod. If Kubernetes cannot find such a condition in the
<code>status.conditions</code> field of a Pod, the status of the condition
is defaulted to "<code>False</code>".</p><p>Here is an example:</p><div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="display:flex"><span><span style="color:green;font-weight:700">kind</span>:<span style="color:#bbb"> </span>Pod<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb"/><span style="color:#00f;font-weight:700">...</span><span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb"/><span style="color:green;font-weight:700">spec</span>:<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">  </span><span style="color:green;font-weight:700">readinessGates</span>:<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">    </span>- <span style="color:green;font-weight:700">conditionType</span>:<span style="color:#bbb"> </span><span style="color:#b44">"www.example.com/feature-1"</span><span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb"/><span style="color:green;font-weight:700">status</span>:<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">  </span><span style="color:green;font-weight:700">conditions</span>:<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">    </span>- <span style="color:green;font-weight:700">type</span>:<span style="color:#bbb"> </span>Ready                             <span style="color:#bbb"> </span><span style="color:#080;font-style:italic"># a built-in PodCondition</span><span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">      </span><span style="color:green;font-weight:700">status</span>:<span style="color:#bbb"> </span><span style="color:#b44">"False"</span><span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">      </span><span style="color:green;font-weight:700">lastProbeTime</span>:<span style="color:#bbb"> </span><span style="color:#a2f;font-weight:700">null</span><span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">      </span><span style="color:green;font-weight:700">lastTransitionTime</span>:<span style="color:#bbb"> </span>2018-01-01T00:00:00Z<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">    </span>- <span style="color:green;font-weight:700">type</span>:<span style="color:#bbb"> </span><span style="color:#b44">"www.example.com/feature-1"</span><span style="color:#bbb">        </span><span style="color:#080;font-style:italic"># an extra PodCondition</span><span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">      </span><span style="color:green;font-weight:700">status</span>:<span style="color:#bbb"> </span><span style="color:#b44">"False"</span><span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">      </span><span style="color:green;font-weight:700">lastProbeTime</span>:<span style="color:#bbb"> </span><span style="color:#a2f;font-weight:700">null</span><span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">      </span><span style="color:green;font-weight:700">lastTransitionTime</span>:<span style="color:#bbb"> </span>2018-01-01T00:00:00Z<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">  </span><span style="color:green;font-weight:700">containerStatuses</span>:<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">    </span>- <span style="color:green;font-weight:700">containerID</span>:<span style="color:#bbb"> </span>docker://abcd...<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">      </span><span style="color:green;font-weight:700">ready</span>:<span style="color:#bbb"> </span><span style="color:#a2f;font-weight:700">true</span><span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb"/><span style="color:#00f;font-weight:700">...</span><span style="color:#bbb">
</span></span></span></code></pre></div><p>The Pod conditions you add must have names that meet the Kubernetes
<a href="/docs/concepts/overview/working-with-objects/labels/#syntax-and-character-set">label key format</a>.</p><h3 id="pod-readiness-status">Status for Pod readiness</h3><p>The <code>kubectl patch</code> command does not support patching object status.
To set these <code>status.conditions</code> for the Pod, applications and
<a class="glossary-tooltip" title="A specialized controller used to manage a custom resource" data-toggle="tooltip" data-placement="top" href="/docs/concepts/extend-kubernetes/operator/" target="_blank" aria-label="operators">operators</a> should use
the <code>PATCH</code> action.
You can use a <a href="/docs/reference/using-api/client-libraries/">Kubernetes client library</a> to
write code that sets custom Pod conditions for Pod readiness.</p><p>For a Pod that uses custom conditions, that Pod is evaluated to be ready <strong>only</strong>
when both the following statements apply:</p><ul><li>All containers in the Pod are ready.</li><li>All conditions specified in <code>readinessGates</code> are <code>True</code>.</li></ul><p>When a Pod's containers are Ready but at least one custom condition is missing or
<code>False</code>, the kubelet sets the Pod's <a href="#pod-conditions">condition</a> to <code>ContainersReady</code>.</p><h3 id="pod-has-network">Pod network readiness</h3><div class="feature-state-notice feature-beta"><span class="feature-state-name">FEATURE STATE:</span>
<code>Kubernetes v1.29 [beta]</code></div><div class="alert alert-info" role="alert"><h4 class="alert-heading">Note:</h4>During its early development, this condition was named <code>PodHasNetwork</code>.</div><p>After a Pod gets scheduled on a node, it needs to be admitted by the kubelet and
to have any required storage volumes mounted. Once these phases are complete,
the kubelet works with
a container runtime (using <a class="glossary-tooltip" title="Protocol for communication between the kubelet and the local container runtime." data-toggle="tooltip" data-placement="top" href="/docs/concepts/architecture/cri" target="_blank" aria-label="Container Runtime Interface (CRI)">Container Runtime Interface (CRI)</a>) to set up a
runtime sandbox and configure networking for the Pod. If the
<code>PodReadyToStartContainersCondition</code>
<a href="/docs/reference/command-line-tools-reference/feature-gates/">feature gate</a> is enabled
(it is enabled by default for Kubernetes 1.34), the
<code>PodReadyToStartContainers</code> condition will be added to the <code>status.conditions</code> field of a Pod.</p><p>The <code>PodReadyToStartContainers</code> condition is set to <code>False</code> by the Kubelet when it detects a
Pod does not have a runtime sandbox with networking configured. This occurs in
the following scenarios:</p><ul><li>Early in the lifecycle of the Pod, when the kubelet has not yet begun to set up a sandbox for
the Pod using the container runtime.</li><li>Later in the lifecycle of the Pod, when the Pod sandbox has been destroyed due to either:<ul><li>the node rebooting, without the Pod getting evicted</li><li>for container runtimes that use virtual machines for isolation, the Pod
sandbox virtual machine rebooting, which then requires creating a new sandbox and
fresh container network configuration.</li></ul></li></ul><p>The <code>PodReadyToStartContainers</code> condition is set to <code>True</code> by the kubelet after the
successful completion of sandbox creation and network configuration for the Pod
by the runtime plugin. The kubelet can start pulling container images and create
containers after <code>PodReadyToStartContainers</code> condition has been set to <code>True</code>.</p><p>For a Pod with init containers, the kubelet sets the <code>Initialized</code> condition to
<code>True</code> after the init containers have successfully completed (which happens
after successful sandbox creation and network configuration by the runtime
plugin). For a Pod without init containers, the kubelet sets the <code>Initialized</code>
condition to <code>True</code> before sandbox creation and network configuration starts.</p><h2 id="container-probes">Container probes</h2><p>A <em>probe</em> is a diagnostic performed periodically by the <a href="/docs/reference/command-line-tools-reference/kubelet/">kubelet</a>
on a container. To perform a diagnostic, the kubelet either executes code within the container,
or makes a network request.</p><h3 id="probe-check-methods">Check mechanisms</h3><p>There are four different ways to check a container using a probe.
Each probe must define exactly one of these four mechanisms:</p><dl><dt><code>exec</code></dt><dd>Executes a specified command inside the container. The diagnostic
is considered successful if the command exits with a status code of 0.</dd><dt><code>grpc</code></dt><dd>Performs a remote procedure call using <a href="https://grpc.io/">gRPC</a>.
The target should implement
<a href="https://grpc.io/grpc/core/md_doc_health-checking.html">gRPC health checks</a>.
The diagnostic is considered successful if the <code>status</code>
of the response is <code>SERVING</code>.</dd><dt><code>httpGet</code></dt><dd>Performs an HTTP <code>GET</code> request against the Pod's IP
address on a specified port and path. The diagnostic is
considered successful if the response has a status code
greater than or equal to 200 and less than 400.</dd><dt><code>tcpSocket</code></dt><dd>Performs a TCP check against the Pod's IP address on
a specified port. The diagnostic is considered successful if
the port is open. If the remote system (the container) closes
the connection immediately after it opens, this counts as healthy.</dd></dl><div class="alert alert-caution" role="alert"><h4 class="alert-heading">Caution:</h4>Unlike the other mechanisms, <code>exec</code> probe's implementation involves
the creation/forking of multiple processes each time when executed.
As a result, in case of the clusters having higher pod densities,
lower intervals of <code>initialDelaySeconds</code>, <code>periodSeconds</code>,
configuring any probe with exec mechanism might introduce an overhead on the cpu usage of the node.
In such scenarios, consider using the alternative probe mechanisms to avoid the overhead.</div><h3 id="probe-outcome">Probe outcome</h3><p>Each probe has one of three results:</p><dl><dt><code>Success</code></dt><dd>The container passed the diagnostic.</dd><dt><code>Failure</code></dt><dd>The container failed the diagnostic.</dd><dt><code>Unknown</code></dt><dd>The diagnostic failed (no action should be taken, and the kubelet
will make further checks).</dd></dl><h3 id="types-of-probe">Types of probe</h3><p>The kubelet can optionally perform and react to three kinds of probes on running
containers:</p><dl><dt><code>livenessProbe</code></dt><dd>Indicates whether the container is running. If
the liveness probe fails, the kubelet kills the container, and the container
is subjected to its <a href="#restart-policy">restart policy</a>. If a container does not
provide a liveness probe, the default state is <code>Success</code>.</dd><dt><code>readinessProbe</code></dt><dd>Indicates whether the container is ready to respond to requests.
If the readiness probe fails, the <a class="glossary-tooltip" title="EndpointSlices track the IP addresses of Pods for Services." data-toggle="tooltip" data-placement="top" href="/docs/concepts/services-networking/endpoint-slices/" target="_blank" aria-label="EndpointSlice">EndpointSlice</a>
controller removes the Pod's IP address from the EndpointSlices of all Services that match the Pod.
The default state of readiness before the initial delay is <code>Failure</code>. If a container does
not provide a readiness probe, the default state is <code>Success</code>.</dd><dt><code>startupProbe</code></dt><dd>Indicates whether the application within the container is started.
All other probes are disabled if a startup probe is provided, until it succeeds.
If the startup probe fails, the kubelet kills the container, and the container
is subjected to its <a href="#restart-policy">restart policy</a>. If a container does not
provide a startup probe, the default state is <code>Success</code>.</dd></dl><p>For more information about how to set up a liveness, readiness, or startup probe,
see <a href="/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/">Configure Liveness, Readiness and Startup Probes</a>.</p><h4 id="when-should-you-use-a-liveness-probe">When should you use a liveness probe?</h4><p>If the process in your container is able to crash on its own whenever it
encounters an issue or becomes unhealthy, you do not necessarily need a liveness
probe; the kubelet will automatically perform the correct action in accordance
with the Pod's <code>restartPolicy</code>.</p><p>If you'd like your container to be killed and restarted if a probe fails, then
specify a liveness probe, and specify a <code>restartPolicy</code> of Always or OnFailure.</p><h4 id="when-should-you-use-a-readiness-probe">When should you use a readiness probe?</h4><p>If you'd like to start sending traffic to a Pod only when a probe succeeds,
specify a readiness probe. In this case, the readiness probe might be the same
as the liveness probe, but the existence of the readiness probe in the spec means
that the Pod will start without receiving any traffic and only start receiving
traffic after the probe starts succeeding.</p><p>If you want your container to be able to take itself down for maintenance, you
can specify a readiness probe that checks an endpoint specific to readiness that
is different from the liveness probe.</p><p>If your app has a strict dependency on back-end services, you can implement both
a liveness and a readiness probe. The liveness probe passes when the app itself
is healthy, but the readiness probe additionally checks that each required
back-end service is available. This helps you avoid directing traffic to Pods
that can only respond with error messages.</p><p>If your container needs to work on loading large data, configuration files, or
migrations during startup, you can use a
<a href="#when-should-you-use-a-startup-probe">startup probe</a>. However, if you want to
detect the difference between an app that has failed and an app that is still
processing its startup data, you might prefer a readiness probe.</p><div class="alert alert-info" role="alert"><h4 class="alert-heading">Note:</h4>If you want to be able to drain requests when the Pod is deleted, you do not
necessarily need a readiness probe; when the Pod is deleted, the corresponding endpoint
in the <code>EndpointSlice</code> will update its <a href="/docs/concepts/services-networking/endpoint-slices/#conditions">conditions</a>:
the endpoint <code>ready</code> condition will be set to <code>false</code>, so load balancers
will not use the Pod for regular traffic. See <a href="#pod-termination">Pod termination</a>
for more information about how the kubelet handles Pod deletion.</div><h4 id="when-should-you-use-a-startup-probe">When should you use a startup probe?</h4><p>Startup probes are useful for Pods that have containers that take a long time to
come into service. Rather than set a long liveness interval, you can configure
a separate configuration for probing the container as it starts up, allowing
a time longer than the liveness interval would allow.</p><p>If your container usually starts in more than
\( initialDelaySeconds + failureThreshold \times periodSeconds \), you should specify a
startup probe that checks the same endpoint as the liveness probe. The default for
<code>periodSeconds</code> is 10s. You should then set its <code>failureThreshold</code> high enough to
allow the container to start, without changing the default values of the liveness
probe. This helps to protect against deadlocks.</p><h2 id="pod-termination">Termination of Pods</h2><p>Because Pods represent processes running on nodes in the cluster, it is important to
allow those processes to gracefully terminate when they are no longer needed (rather
than being abruptly stopped with a <code>KILL</code> signal and having no chance to clean up).</p><p>The design aim is for you to be able to request deletion and know when processes
terminate, but also be able to ensure that deletes eventually complete.
When you request deletion of a Pod, the cluster records and tracks the intended grace period
before the Pod is allowed to be forcefully killed. With that forceful shutdown tracking in
place, the <a class="glossary-tooltip" title="An agent that runs on each node in the cluster. It makes sure that containers are running in a pod." data-toggle="tooltip" data-placement="top" href="/docs/reference/command-line-tools-reference/kubelet" target="_blank" aria-label="kubelet">kubelet</a> attempts graceful
shutdown.</p><p>Typically, with this graceful termination of the pod, kubelet makes requests to the container runtime
to attempt to stop the containers in the pod by first sending a TERM (aka. SIGTERM) signal,
with a grace period timeout, to the main process in each container.
The requests to stop the containers are processed by the container runtime asynchronously.
There is no guarantee to the order of processing for these requests.
Many container runtimes respect the <code>STOPSIGNAL</code> value defined in the container image and,
if different, send the container image configured STOPSIGNAL instead of TERM.
Once the grace period has expired, the KILL signal is sent to any remaining
processes, and the Pod is then deleted from the
<a class="glossary-tooltip" title="Control plane component that serves the Kubernetes API." data-toggle="tooltip" data-placement="top" href="/docs/concepts/architecture/#kube-apiserver" target="_blank" aria-label="API Server">API Server</a>. If the kubelet or the
container runtime's management service is restarted while waiting for processes to terminate, the
cluster retries from the start including the full original grace period.</p><h3 id="pod-termination-stop-signals">Stop Signals</h3><p>The stop signal used to kill the container can be defined in the container image with the <code>STOPSIGNAL</code> instruction.
If no stop signal is defined in the image, the default signal of the container runtime
(SIGTERM for both containerd and CRI-O) would be used to kill the container.</p><h3 id="defining-custom-stop-signals">Defining custom stop signals</h3><div class="feature-state-notice feature-alpha" title="Feature Gate: ContainerStopSignals"><span class="feature-state-name">FEATURE STATE:</span>
<code>Kubernetes v1.33 [alpha]</code> (enabled by default: false)</div><p>If the <code>ContainerStopSignals</code> feature gate is enabled, you can configure a custom stop signal
for your containers from the container Lifecycle. We require the Pod's <code>spec.os.name</code> field
to be present as a requirement for defining stop signals in the container lifecycle.
The list of signals that are valid depends on the OS the Pod is scheduled to.
For Pods scheduled to Windows nodes, we only support SIGTERM and SIGKILL as valid signals.</p><p>Here is an example Pod spec defining a custom stop signal:</p><div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="display:flex"><span><span style="color:green;font-weight:700">spec</span>:<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">  </span><span style="color:green;font-weight:700">os</span>:<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">    </span><span style="color:green;font-weight:700">name</span>:<span style="color:#bbb"> </span>linux<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">  </span><span style="color:green;font-weight:700">containers</span>:<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">    </span>- <span style="color:green;font-weight:700">name</span>:<span style="color:#bbb"> </span>my-container<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">      </span><span style="color:green;font-weight:700">image</span>:<span style="color:#bbb"> </span>container-image:latest<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">      </span><span style="color:green;font-weight:700">lifecycle</span>:<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">        </span><span style="color:green;font-weight:700">stopSignal</span>:<span style="color:#bbb"> </span>SIGUSR1<span style="color:#bbb">
</span></span></span></code></pre></div><p>If a stop signal is defined in the lifecycle, this will override the signal defined in the container image.
If no stop signal is defined in the container spec, the container would fall back to the default behavior.</p><h3 id="pod-termination-flow">Pod Termination Flow</h3><p>Pod termination flow, illustrated with an example:</p><ol><li><p>You use the <code>kubectl</code> tool to manually delete a specific Pod, with the default grace period
(30 seconds).</p></li><li><p>The Pod in the API server is updated with the time beyond which the Pod is considered "dead"
along with the grace period.
If you use <code>kubectl describe</code> to check the Pod you're deleting, that Pod shows up as "Terminating".
On the node where the Pod is running: as soon as the kubelet sees that a Pod has been marked
as terminating (a graceful shutdown duration has been set), the kubelet begins the local Pod
shutdown process.</p><ol><li><p>If one of the Pod's containers has defined a <code>preStop</code>
<a href="/docs/concepts/containers/container-lifecycle-hooks/">hook</a> and the <code>terminationGracePeriodSeconds</code>
in the Pod spec is not set to 0, the kubelet runs that hook inside of the container.
The default <code>terminationGracePeriodSeconds</code> setting is 30 seconds.</p><p>If the <code>preStop</code> hook is still running after the grace period expires, the kubelet requests
a small, one-off grace period extension of 2 seconds.<div class="alert alert-info" role="alert"><h4 class="alert-heading">Note:</h4>If the <code>preStop</code> hook needs longer to complete than the default grace period allows,
you must modify <code>terminationGracePeriodSeconds</code> to suit this.</div></p></li><li><p>The kubelet triggers the container runtime to send a TERM signal to process 1 inside each
container.</p><p>There is <a href="#termination-with-sidecars">special ordering</a> if the Pod has any
<a class="glossary-tooltip" title="An auxilliary container that stays running throughout the lifecycle of a Pod." data-toggle="tooltip" data-placement="top" href="/docs/concepts/workloads/pods/sidecar-containers/" target="_blank" aria-label="sidecar containers">sidecar containers</a> defined.
Otherwise, the containers in the Pod receive the TERM signal at different times and in
an arbitrary order. If the order of shutdowns matters, consider using a <code>preStop</code> hook
to synchronize (or switch to using sidecar containers).</p></li></ol></li><li><p>At the same time as the kubelet is starting graceful shutdown of the Pod, the control plane
evaluates whether to remove that shutting-down Pod from EndpointSlice objects,
where those objects represent a <a class="glossary-tooltip" title="A way to expose an application running on a set of Pods as a network service." data-toggle="tooltip" data-placement="top" href="/docs/concepts/services-networking/service/" target="_blank" aria-label="Service">Service</a>
with a configured <a class="glossary-tooltip" title="Allows users to filter a list of resources based on labels." data-toggle="tooltip" data-placement="top" href="/docs/concepts/overview/working-with-objects/labels/" target="_blank" aria-label="selector">selector</a>.
<a class="glossary-tooltip" title="ReplicaSet ensures that a specified number of Pod replicas are running at one time" data-toggle="tooltip" data-placement="top" href="/docs/concepts/workloads/controllers/replicaset/" target="_blank" aria-label="ReplicaSets">ReplicaSets</a> and other workload resources
no longer treat the shutting-down Pod as a valid, in-service replica.</p><p>Pods that shut down slowly should not continue to serve regular traffic and should start
terminating and finish processing open connections. Some applications need to go beyond
finishing open connections and need more graceful termination, for example, session draining
and completion.</p><p>Any endpoints that represent the terminating Pods are not immediately removed from
EndpointSlices, and a status indicating <a href="/docs/concepts/services-networking/endpoint-slices/#conditions">terminating state</a>
is exposed from the EndpointSlice API.
Terminating endpoints always have their <code>ready</code> status as <code>false</code> (for backward compatibility
with versions before 1.26), so load balancers will not use it for regular traffic.</p><p>If traffic draining on terminating Pod is needed, the actual readiness can be checked as a
condition <code>serving</code>. You can find more details on how to implement connections draining in the
tutorial <a href="/docs/tutorials/services/pods-and-endpoint-termination-flow/">Pods And Endpoints Termination Flow</a></p><a id="pod-termination-beyond-grace-period"/></li><li><p>The kubelet ensures the Pod is shut down and terminated</p><ol><li>When the grace period expires, if there is still any container running in the Pod, the
kubelet triggers forcible shutdown.
The container runtime sends <code>SIGKILL</code> to any processes still running in any container in the Pod.
The kubelet also cleans up a hidden <code>pause</code> container if that container runtime uses one.</li><li>The kubelet transitions the Pod into a terminal phase (<code>Failed</code> or <code>Succeeded</code> depending on
the end state of its containers).</li><li>The kubelet triggers forcible removal of the Pod object from the API server, by setting grace period
to 0 (immediate deletion).</li><li>The API server deletes the Pod's API object, which is then no longer visible from any client.</li></ol></li></ol><h3 id="pod-termination-forced">Forced Pod termination</h3><div class="alert alert-caution" role="alert"><h4 class="alert-heading">Caution:</h4>Forced deletions can be potentially disruptive for some workloads and their Pods.</div><p>By default, all deletes are graceful within 30 seconds. The <code>kubectl delete</code> command supports
the <code>--grace-period=&lt;seconds&gt;</code> option which allows you to override the default and specify your
own value.</p><p>Setting the grace period to <code>0</code> forcibly and immediately deletes the Pod from the API
server. If the Pod was still running on a node, that forcible deletion triggers the kubelet to
begin immediate cleanup.</p><p>Using kubectl, You must specify an additional flag <code>--force</code> along with <code>--grace-period=0</code>
in order to perform force deletions.</p><p>When a force deletion is performed, the API server does not wait for confirmation
from the kubelet that the Pod has been terminated on the node it was running on. It
removes the Pod in the API immediately so a new Pod can be created with the same
name. On the node, Pods that are set to terminate immediately will still be given
a small grace period before being force killed.</p><div class="alert alert-caution" role="alert"><h4 class="alert-heading">Caution:</h4>Immediate deletion does not wait for confirmation that the running resource has been terminated.
The resource may continue to run on the cluster indefinitely.</div><p>If you need to force-delete Pods that are part of a StatefulSet, refer to the task
documentation for
<a href="/docs/tasks/run-application/force-delete-stateful-set-pod/">deleting Pods from a StatefulSet</a>.</p><h3 id="termination-with-sidecars">Pod shutdown and sidecar containers</h3><p>If your Pod includes one or more
<a href="/docs/concepts/workloads/pods/sidecar-containers/">sidecar containers</a>
(init containers with an Always restart policy), the kubelet will delay sending
the TERM signal to these sidecar containers until the last main container has fully terminated.
The sidecar containers will be terminated in the reverse order they are defined in the Pod spec.
This ensures that sidecar containers continue serving the other containers in the Pod until they
are no longer needed.</p><p>This means that slow termination of a main container will also delay the termination of the sidecar containers.
If the grace period expires before the termination process is complete, the Pod may enter <a href="#pod-termination-beyond-grace-period">forced termination</a>.
In this case, all remaining containers in the Pod will be terminated simultaneously with a short grace period.</p><p>Similarly, if the Pod has a <code>preStop</code> hook that exceeds the termination grace period, emergency termination may occur.
In general, if you have used <code>preStop</code> hooks to control the termination order without sidecar containers, you can now
remove them and allow the kubelet to manage sidecar termination automatically.</p><h3 id="pod-garbage-collection">Garbage collection of Pods</h3><p>For failed Pods, the API objects remain in the cluster's API until a human or
<a class="glossary-tooltip" title="A control loop that watches the shared state of the cluster through the apiserver and makes changes attempting to move the current state towards the desired state." data-toggle="tooltip" data-placement="top" href="/docs/concepts/architecture/controller/" target="_blank" aria-label="controller">controller</a> process
explicitly removes them.</p><p>The Pod garbage collector (PodGC), which is a controller in the control plane, cleans up
terminated Pods (with a phase of <code>Succeeded</code> or <code>Failed</code>), when the number of Pods exceeds the
configured threshold (determined by <code>terminated-pod-gc-threshold</code> in the kube-controller-manager).
This avoids a resource leak as Pods are created and terminated over time.</p><p>Additionally, PodGC cleans up any Pods which satisfy any of the following conditions:</p><ol><li>are orphan Pods - bound to a node which no longer exists,</li><li>are unscheduled terminating Pods,</li><li>are terminating Pods, bound to a non-ready node tainted with
<a href="/docs/reference/labels-annotations-taints/#node-kubernetes-io-out-of-service"><code>node.kubernetes.io/out-of-service</code></a>.</li></ol><p>Along with cleaning up the Pods, PodGC will also mark them as failed if they are in a non-terminal
phase. Also, PodGC adds a Pod disruption condition when cleaning up an orphan Pod.
See <a href="/docs/concepts/workloads/pods/disruptions/#pod-disruption-conditions">Pod disruption conditions</a>
for more details.</p><h2 id="what-s-next">What's next</h2><ul><li><p>Get hands-on experience
<a href="/docs/tasks/configure-pod-container/attach-handler-lifecycle-event/">attaching handlers to container lifecycle events</a>.</p></li><li><p>Get hands-on experience
<a href="/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/">configuring Liveness, Readiness and Startup Probes</a>.</p></li><li><p>Learn more about <a href="/docs/concepts/containers/container-lifecycle-hooks/">container lifecycle hooks</a>.</p></li><li><p>Learn more about <a href="/docs/concepts/workloads/pods/sidecar-containers/">sidecar containers</a>.</p></li><li><p>For detailed information about Pod and container status in the API, see
the API reference documentation covering
<a href="/docs/reference/kubernetes-api/workload-resources/pod-v1/#PodStatus"><code>status</code></a> for Pod.</p></li></ul></div>