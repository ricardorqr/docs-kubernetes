<div class="td-content"><h1 data-pagefind-weight="10">Schedule GPUs</h1><div class="lead">Configure and schedule GPUs for use as a resource by nodes in a cluster.</div><div class="feature-state-notice feature-stable"><span class="feature-state-name">FEATURE STATE:</span>
<code>Kubernetes v1.26 [stable]</code></div><p>Kubernetes includes <strong>stable</strong> support for managing AMD and NVIDIA GPUs
(graphical processing units) across different nodes in your cluster, using
<a class="glossary-tooltip" title="Software extensions to let Pods access devices that need vendor-specific initialization or setup" data-toggle="tooltip" data-placement="top" href="/docs/concepts/extend-kubernetes/compute-storage-net/device-plugins/" target="_blank" aria-label="device plugins">device plugins</a>.</p><p>This page describes how users can consume GPUs, and outlines
some of the limitations in the implementation.</p><h2 id="using-device-plugins">Using device plugins</h2><p>Kubernetes implements device plugins to let Pods access specialized hardware features such as GPUs.</p><div class="alert alert-secondary callout third-party-content" role="alert"><strong>Note:</strong>â€ˆThis section links to third party projects that provide functionality required by Kubernetes. The Kubernetes project authors aren't responsible for these projects, which are listed alphabetically. To add a project to this list, read the <a href="/docs/contribute/style/content-guide/#third-party-content">content guide</a> before submitting a change. <a href="#third-party-content-disclaimer">More information.</a></div><p>As an administrator, you have to install GPU drivers from the corresponding
hardware vendor on the nodes and run the corresponding device plugin from the
GPU vendor. Here are some links to vendors' instructions:</p><ul><li><a href="https://github.com/ROCm/k8s-device-plugin#deployment">AMD</a></li><li><a href="https://intel.github.io/intel-device-plugins-for-kubernetes/cmd/gpu_plugin/README.html">Intel</a></li><li><a href="https://github.com/NVIDIA/k8s-device-plugin#quick-start">NVIDIA</a></li></ul><p>Once you have installed the plugin, your cluster exposes a custom schedulable resource such as <code>amd.com/gpu</code> or <code>nvidia.com/gpu</code>.</p><p>You can consume these GPUs from your containers by requesting
the custom GPU resource, the same way you request <code>cpu</code> or <code>memory</code>.
However, there are some limitations in how you specify the resource
requirements for custom devices.</p><p>GPUs are only supposed to be specified in the <code>limits</code> section, which means:</p><ul><li>You can specify GPU <code>limits</code> without specifying <code>requests</code>, because
Kubernetes will use the limit as the request value by default.</li><li>You can specify GPU in both <code>limits</code> and <code>requests</code> but these two values
must be equal.</li><li>You cannot specify GPU <code>requests</code> without specifying <code>limits</code>.</li></ul><p>Here's an example manifest for a Pod that requests a GPU:</p><div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="display:flex"><span><span style="color:green;font-weight:700">apiVersion</span>:<span style="color:#bbb"> </span>v1<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb"/><span style="color:green;font-weight:700">kind</span>:<span style="color:#bbb"> </span>Pod<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb"/><span style="color:green;font-weight:700">metadata</span>:<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">  </span><span style="color:green;font-weight:700">name</span>:<span style="color:#bbb"> </span>example-vector-add<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb"/><span style="color:green;font-weight:700">spec</span>:<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">  </span><span style="color:green;font-weight:700">restartPolicy</span>:<span style="color:#bbb"> </span>OnFailure<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">  </span><span style="color:green;font-weight:700">containers</span>:<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">    </span>- <span style="color:green;font-weight:700">name</span>:<span style="color:#bbb"> </span>example-vector-add<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">      </span><span style="color:green;font-weight:700">image</span>:<span style="color:#bbb"> </span><span style="color:#b44">"registry.example/example-vector-add:v42"</span><span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">      </span><span style="color:green;font-weight:700">resources</span>:<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">        </span><span style="color:green;font-weight:700">limits</span>:<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">          </span><span style="color:green;font-weight:700">gpu-vendor.example/example-gpu</span>:<span style="color:#bbb"> </span><span style="color:#666">1</span><span style="color:#bbb"> </span><span style="color:#080;font-style:italic"># requesting 1 GPU</span><span style="color:#bbb">
</span></span></span></code></pre></div><h2 id="manage-clusters-with-different-types-of-gpus">Manage clusters with different types of GPUs</h2><p>If different nodes in your cluster have different types of GPUs, then you
can use <a href="/docs/tasks/configure-pod-container/assign-pods-nodes/">Node Labels and Node Selectors</a>
to schedule pods to appropriate nodes.</p><p>For example:</p><div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell"><span style="display:flex"><span><span style="color:#080;font-style:italic"># Label your nodes with the accelerator type they have.</span>
</span></span><span style="display:flex"><span>kubectl label nodes node1 <span style="color:#b8860b">accelerator</span><span style="color:#666">=</span>example-gpu-x100
</span></span><span style="display:flex"><span>kubectl label nodes node2 <span style="color:#b8860b">accelerator</span><span style="color:#666">=</span>other-gpu-k915
</span></span></code></pre></div><p>That label key <code>accelerator</code> is just an example; you can use
a different label key if you prefer.</p><h2 id="node-labeller">Automatic node labelling</h2><p>As an administrator, you can automatically discover and label all your GPU enabled nodes
by deploying Kubernetes <a href="https://github.com/kubernetes-sigs/node-feature-discovery">Node Feature Discovery</a> (NFD).
NFD detects the hardware features that are available on each node in a Kubernetes cluster.
Typically, NFD is configured to advertise those features as node labels, but NFD can also add extended resources, annotations, and node taints.
NFD is compatible with all <a href="/releases/version-skew-policy/#supported-versions">supported versions</a> of Kubernetes.
By default NFD create the <a href="https://kubernetes-sigs.github.io/node-feature-discovery/master/usage/features.html">feature labels</a> for the detected features.
Administrators can leverage NFD to also taint nodes with specific features, so that only pods that request those features can be scheduled on those nodes.</p><p>You also need a plugin for NFD that adds appropriate labels to your nodes; these might be generic
labels or they could be vendor specific. Your GPU vendor may provide a third party
plugin for NFD; check their documentation for more details.</p><div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;display:grid"><code class="language-yaml" data-lang="yaml"><span style="display:flex"><span><span style="color:green;font-weight:700">apiVersion</span>:<span style="color:#bbb"> </span>v1<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb"/><span style="color:green;font-weight:700">kind</span>:<span style="color:#bbb"> </span>Pod<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb"/><span style="color:green;font-weight:700">metadata</span>:<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">  </span><span style="color:green;font-weight:700">name</span>:<span style="color:#bbb"> </span>example-vector-add<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb"/><span style="color:green;font-weight:700">spec</span>:<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">  </span><span style="color:green;font-weight:700">restartPolicy</span>:<span style="color:#bbb"> </span>OnFailure<span style="color:#bbb">
</span></span></span><span style="display:flex;background-color:#dfdfdf"><span><span style="color:#bbb">  </span><span style="color:#080;font-style:italic"># You can use Kubernetes node affinity to schedule this Pod onto a node</span><span style="color:#bbb">
</span></span></span><span style="display:flex;background-color:#dfdfdf"><span><span style="color:#bbb">  </span><span style="color:#080;font-style:italic"># that provides the kind of GPU that its container needs in order to work</span><span style="color:#bbb">
</span></span></span><span style="display:flex;background-color:#dfdfdf"><span><span style="color:#bbb">  </span><span style="color:green;font-weight:700">affinity</span>:<span style="color:#bbb">
</span></span></span><span style="display:flex;background-color:#dfdfdf"><span><span style="color:#bbb">    </span><span style="color:green;font-weight:700">nodeAffinity</span>:<span style="color:#bbb">
</span></span></span><span style="display:flex;background-color:#dfdfdf"><span><span style="color:#bbb">      </span><span style="color:green;font-weight:700">requiredDuringSchedulingIgnoredDuringExecution</span>:<span style="color:#bbb">
</span></span></span><span style="display:flex;background-color:#dfdfdf"><span><span style="color:#bbb">        </span><span style="color:green;font-weight:700">nodeSelectorTerms</span>:<span style="color:#bbb">
</span></span></span><span style="display:flex;background-color:#dfdfdf"><span><span style="color:#bbb">        </span>- <span style="color:green;font-weight:700">matchExpressions</span>:<span style="color:#bbb">
</span></span></span><span style="display:flex;background-color:#dfdfdf"><span><span style="color:#bbb">          </span>- <span style="color:green;font-weight:700">key</span>:<span style="color:#bbb"> </span><span style="color:#b44">"gpu.gpu-vendor.example/installed-memory"</span><span style="color:#bbb">
</span></span></span><span style="display:flex;background-color:#dfdfdf"><span><span style="color:#bbb">            </span><span style="color:green;font-weight:700">operator</span>:<span style="color:#bbb"> </span>Gt<span style="color:#bbb"> </span><span style="color:#080;font-style:italic"># (greater than)</span><span style="color:#bbb">
</span></span></span><span style="display:flex;background-color:#dfdfdf"><span><span style="color:#bbb">            </span><span style="color:green;font-weight:700">values</span>:<span style="color:#bbb"> </span>[<span style="color:#b44">"40535"</span>]<span style="color:#bbb">
</span></span></span><span style="display:flex;background-color:#dfdfdf"><span><span style="color:#bbb">          </span>- <span style="color:green;font-weight:700">key</span>:<span style="color:#bbb"> </span><span style="color:#b44">"feature.node.kubernetes.io/pci-10.present"</span><span style="color:#bbb"> </span><span style="color:#080;font-style:italic"># NFD Feature label</span><span style="color:#bbb">
</span></span></span><span style="display:flex;background-color:#dfdfdf"><span><span style="color:#bbb">            </span><span style="color:green;font-weight:700">values</span>:<span style="color:#bbb"> </span>[<span style="color:#b44">"true"</span>]<span style="color:#bbb"> </span><span style="color:#080;font-style:italic"># (optional) only schedule on nodes with PCI device 10</span><span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">  </span><span style="color:green;font-weight:700">containers</span>:<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">    </span>- <span style="color:green;font-weight:700">name</span>:<span style="color:#bbb"> </span>example-vector-add<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">      </span><span style="color:green;font-weight:700">image</span>:<span style="color:#bbb"> </span><span style="color:#b44">"registry.example/example-vector-add:v42"</span><span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">      </span><span style="color:green;font-weight:700">resources</span>:<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">        </span><span style="color:green;font-weight:700">limits</span>:<span style="color:#bbb">
</span></span></span><span style="display:flex"><span><span style="color:#bbb">          </span><span style="color:green;font-weight:700">gpu-vendor.example/example-gpu</span>:<span style="color:#bbb"> </span><span style="color:#666">1</span><span style="color:#bbb"> </span><span style="color:#080;font-style:italic"># requesting 1 GPU</span></span></span></code></pre></div><h4 id="gpu-vendor-implementations">GPU vendor implementations</h4><ul><li><a href="https://intel.github.io/intel-device-plugins-for-kubernetes/cmd/gpu_plugin/README.html">Intel</a></li><li><a href="https://github.com/NVIDIA/k8s-device-plugin">NVIDIA</a></li></ul></div>