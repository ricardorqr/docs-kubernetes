<div class="td-content"><h1 data-pagefind-weight="10">Disruptions</h1><p>This guide is for application owners who want to build
highly available applications, and thus need to understand
what types of disruptions can happen to Pods.</p><p>It is also for cluster administrators who want to perform automated
cluster actions, like upgrading and autoscaling clusters.</p><h2 id="voluntary-and-involuntary-disruptions">Voluntary and involuntary disruptions</h2><p>Pods do not disappear until someone (a person or a controller) destroys them, or
there is an unavoidable hardware or system software error.</p><p>We call these unavoidable cases <em>involuntary disruptions</em> to
an application. Examples are:</p><ul><li>a hardware failure of the physical machine backing the node</li><li>cluster administrator deletes VM (instance) by mistake</li><li>cloud provider or hypervisor failure makes VM disappear</li><li>a kernel panic</li><li>the node disappears from the cluster due to cluster network partition</li><li>eviction of a pod due to the node being <a href="/docs/concepts/scheduling-eviction/node-pressure-eviction/">out-of-resources</a>.</li></ul><p>Except for the out-of-resources condition, all these conditions
should be familiar to most users; they are not specific
to Kubernetes.</p><p>We call other cases <em>voluntary disruptions</em>. These include both
actions initiated by the application owner and those initiated by a Cluster
Administrator. Typical application owner actions include:</p><ul><li>deleting the deployment or other controller that manages the pod</li><li>updating a deployment's pod template causing a restart</li><li>directly deleting a pod (e.g. by accident)</li></ul><p>Cluster administrator actions include:</p><ul><li><a href="/docs/tasks/administer-cluster/safely-drain-node/">Draining a node</a> for repair or upgrade.</li><li>Draining a node from a cluster to scale the cluster down (learn about
<a href="/docs/concepts/cluster-administration/node-autoscaling/">Node Autoscaling</a>).</li><li>Removing a pod from a node to permit something else to fit on that node.</li></ul><p>These actions might be taken directly by the cluster administrator, or by automation
run by the cluster administrator, or by your cluster hosting provider.</p><p>Ask your cluster administrator or consult your cloud provider or distribution documentation
to determine if any sources of voluntary disruptions are enabled for your cluster.
If none are enabled, you can skip creating Pod Disruption Budgets.</p><div class="alert alert-caution" role="alert"><h4 class="alert-heading">Caution:</h4>Not all voluntary disruptions are constrained by Pod Disruption Budgets. For example,
deleting deployments or pods bypasses Pod Disruption Budgets.</div><h2 id="dealing-with-disruptions">Dealing with disruptions</h2><p>Here are some ways to mitigate involuntary disruptions:</p><ul><li>Ensure your pod <a href="/docs/tasks/configure-pod-container/assign-memory-resource/">requests the resources</a> it needs.</li><li>Replicate your application if you need higher availability. (Learn about running replicated
<a href="/docs/tasks/run-application/run-stateless-application-deployment/">stateless</a>
and <a href="/docs/tasks/run-application/run-replicated-stateful-application/">stateful</a> applications.)</li><li>For even higher availability when running replicated applications,
spread applications across racks (using
<a href="/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity">anti-affinity</a>)
or across zones (if using a
<a href="/docs/setup/multiple-zones">multi-zone cluster</a>.)</li></ul><p>The frequency of voluntary disruptions varies. On a basic Kubernetes cluster, there are
no automated voluntary disruptions (only user-triggered ones). However, your cluster administrator or hosting provider
may run some additional services which cause voluntary disruptions. For example,
rolling out node software updates can cause voluntary disruptions. Also, some implementations
of cluster (node) autoscaling may cause voluntary disruptions to defragment and compact nodes.
Your cluster administrator or hosting provider should have documented what level of voluntary
disruptions, if any, to expect. Certain configuration options, such as
<a href="/docs/concepts/scheduling-eviction/pod-priority-preemption/">using PriorityClasses</a>
in your pod spec can also cause voluntary (and involuntary) disruptions.</p><h2 id="pod-disruption-budgets">Pod disruption budgets</h2><div class="feature-state-notice feature-stable"><span class="feature-state-name">FEATURE STATE:</span>
<code>Kubernetes v1.21 [stable]</code></div><p>Kubernetes offers features to help you run highly available applications even when you
introduce frequent voluntary disruptions.</p><p>As an application owner, you can create a PodDisruptionBudget (PDB) for each application.
A PDB limits the number of Pods of a replicated application that are down simultaneously from
voluntary disruptions. For example, a quorum-based application would
like to ensure that the number of replicas running is never brought below the
number needed for a quorum. A web front end might want to
ensure that the number of replicas serving load never falls below a certain
percentage of the total.</p><p>Cluster managers and hosting providers should use tools which
respect PodDisruptionBudgets by calling the <a href="/docs/tasks/administer-cluster/safely-drain-node/#eviction-api">Eviction API</a>
instead of directly deleting pods or deployments.</p><p>For example, the <code>kubectl drain</code> subcommand lets you mark a node as going out of
service. When you run <code>kubectl drain</code>, the tool tries to evict all of the Pods on
the Node you're taking out of service. The eviction request that <code>kubectl</code> submits on
your behalf may be temporarily rejected, so the tool periodically retries all failed
requests until all Pods on the target node are terminated, or until a configurable timeout
is reached.</p><p>A PDB specifies the number of replicas that an application can tolerate having, relative to how
many it is intended to have. For example, a Deployment which has a <code>.spec.replicas: 5</code> is
supposed to have 5 pods at any given time. If its PDB allows for there to be 4 at a time,
then the Eviction API will allow voluntary disruption of one (but not two) pods at a time.</p><p>The group of pods that comprise the application is specified using a label selector, the same
as the one used by the application's controller (deployment, stateful-set, etc).</p><p>The "intended" number of pods is computed from the <code>.spec.replicas</code> of the workload resource
that is managing those pods. The control plane discovers the owning workload resource by
examining the <code>.metadata.ownerReferences</code> of the Pod.</p><p><a href="#voluntary-and-involuntary-disruptions">Involuntary disruptions</a> cannot be prevented by PDBs; however they
do count against the budget.</p><p>Pods which are deleted or unavailable due to a rolling upgrade to an application do count
against the disruption budget, but workload resources (such as Deployment and StatefulSet)
are not limited by PDBs when doing rolling upgrades. Instead, the handling of failures
during application updates is configured in the spec for the specific workload resource.</p><p>It is recommended to set <code>AlwaysAllow</code> <a href="/docs/tasks/run-application/configure-pdb/#unhealthy-pod-eviction-policy">Unhealthy Pod Eviction Policy</a>
to your PodDisruptionBudgets to support eviction of misbehaving applications during a node drain.
The default behavior is to wait for the application pods to become <a href="/docs/tasks/run-application/configure-pdb/#healthiness-of-a-pod">healthy</a>
before the drain can proceed.</p><p>When a pod is evicted using the eviction API, it is gracefully
<a href="/docs/concepts/workloads/pods/pod-lifecycle/#pod-termination">terminated</a>, honoring the
<code>terminationGracePeriodSeconds</code> setting in its <a href="/docs/reference/generated/kubernetes-api/v1.34/#podspec-v1-core">PodSpec</a>.</p><h2 id="pdb-example">PodDisruptionBudget example</h2><p>Consider a cluster with 3 nodes, <code>node-1</code> through <code>node-3</code>.
The cluster is running several applications. One of them has 3 replicas initially called
<code>pod-a</code>, <code>pod-b</code>, and <code>pod-c</code>. Another, unrelated pod without a PDB, called <code>pod-x</code>, is also shown.
Initially, the pods are laid out as follows:</p><table><thead><tr><th style="text-align:center">node-1</th><th style="text-align:center">node-2</th><th style="text-align:center">node-3</th></tr></thead><tbody><tr><td style="text-align:center">pod-a <em>available</em></td><td style="text-align:center">pod-b <em>available</em></td><td style="text-align:center">pod-c <em>available</em></td></tr><tr><td style="text-align:center">pod-x <em>available</em></td><td style="text-align:center"/><td style="text-align:center"/></tr></tbody></table><p>All 3 pods are part of a deployment, and they collectively have a PDB which requires
there be at least 2 of the 3 pods to be available at all times.</p><p>For example, assume the cluster administrator wants to reboot into a new kernel version to fix a bug in the kernel.
The cluster administrator first tries to drain <code>node-1</code> using the <code>kubectl drain</code> command.
That tool tries to evict <code>pod-a</code> and <code>pod-x</code>. This succeeds immediately.
Both pods go into the <code>terminating</code> state at the same time.
This puts the cluster in this state:</p><table><thead><tr><th style="text-align:center">node-1 <em>draining</em></th><th style="text-align:center">node-2</th><th style="text-align:center">node-3</th></tr></thead><tbody><tr><td style="text-align:center">pod-a <em>terminating</em></td><td style="text-align:center">pod-b <em>available</em></td><td style="text-align:center">pod-c <em>available</em></td></tr><tr><td style="text-align:center">pod-x <em>terminating</em></td><td style="text-align:center"/><td style="text-align:center"/></tr></tbody></table><p>The deployment notices that one of the pods is terminating, so it creates a replacement
called <code>pod-d</code>. Since <code>node-1</code> is cordoned, it lands on another node. Something has
also created <code>pod-y</code> as a replacement for <code>pod-x</code>.</p><p>(Note: for a StatefulSet, <code>pod-a</code>, which would be called something like <code>pod-0</code>, would need
to terminate completely before its replacement, which is also called <code>pod-0</code> but has a
different UID, could be created. Otherwise, the example applies to a StatefulSet as well.)</p><p>Now the cluster is in this state:</p><table><thead><tr><th style="text-align:center">node-1 <em>draining</em></th><th style="text-align:center">node-2</th><th style="text-align:center">node-3</th></tr></thead><tbody><tr><td style="text-align:center">pod-a <em>terminating</em></td><td style="text-align:center">pod-b <em>available</em></td><td style="text-align:center">pod-c <em>available</em></td></tr><tr><td style="text-align:center">pod-x <em>terminating</em></td><td style="text-align:center">pod-d <em>starting</em></td><td style="text-align:center">pod-y</td></tr></tbody></table><p>At some point, the pods terminate, and the cluster looks like this:</p><table><thead><tr><th style="text-align:center">node-1 <em>drained</em></th><th style="text-align:center">node-2</th><th style="text-align:center">node-3</th></tr></thead><tbody><tr><td style="text-align:center"/><td style="text-align:center">pod-b <em>available</em></td><td style="text-align:center">pod-c <em>available</em></td></tr><tr><td style="text-align:center"/><td style="text-align:center">pod-d <em>starting</em></td><td style="text-align:center">pod-y</td></tr></tbody></table><p>At this point, if an impatient cluster administrator tries to drain <code>node-2</code> or
<code>node-3</code>, the drain command will block, because there are only 2 available
pods for the deployment, and its PDB requires at least 2. After some time passes, <code>pod-d</code> becomes available.</p><p>The cluster state now looks like this:</p><table><thead><tr><th style="text-align:center">node-1 <em>drained</em></th><th style="text-align:center">node-2</th><th style="text-align:center">node-3</th></tr></thead><tbody><tr><td style="text-align:center"/><td style="text-align:center">pod-b <em>available</em></td><td style="text-align:center">pod-c <em>available</em></td></tr><tr><td style="text-align:center"/><td style="text-align:center">pod-d <em>available</em></td><td style="text-align:center">pod-y</td></tr></tbody></table><p>Now, the cluster administrator tries to drain <code>node-2</code>.
The drain command will try to evict the two pods in some order, say
<code>pod-b</code> first and then <code>pod-d</code>. It will succeed at evicting <code>pod-b</code>.
But, when it tries to evict <code>pod-d</code>, it will be refused because that would leave only
one pod available for the deployment.</p><p>The deployment creates a replacement for <code>pod-b</code> called <code>pod-e</code>.
Because there are not enough resources in the cluster to schedule
<code>pod-e</code> the drain will again block. The cluster may end up in this
state:</p><table><thead><tr><th style="text-align:center">node-1 <em>drained</em></th><th style="text-align:center">node-2</th><th style="text-align:center">node-3</th><th style="text-align:center"><em>no node</em></th></tr></thead><tbody><tr><td style="text-align:center"/><td style="text-align:center">pod-b <em>terminating</em></td><td style="text-align:center">pod-c <em>available</em></td><td style="text-align:center">pod-e <em>pending</em></td></tr><tr><td style="text-align:center"/><td style="text-align:center">pod-d <em>available</em></td><td style="text-align:center">pod-y</td><td style="text-align:center"/></tr></tbody></table><p>At this point, the cluster administrator needs to
add a node back to the cluster to proceed with the upgrade.</p><p>You can see how Kubernetes varies the rate at which disruptions
can happen, according to:</p><ul><li>how many replicas an application needs</li><li>how long it takes to gracefully shutdown an instance</li><li>how long it takes a new instance to start up</li><li>the type of controller</li><li>the cluster's resource capacity</li></ul><h2 id="pod-disruption-conditions">Pod disruption conditions</h2><div class="feature-state-notice feature-stable" title="Feature Gate: PodDisruptionConditions"><span class="feature-state-name">FEATURE STATE:</span>
<code>Kubernetes v1.31 [stable]</code> (enabled by default: true)</div><p>A dedicated Pod <code>DisruptionTarget</code> <a href="/docs/concepts/workloads/pods/pod-lifecycle/#pod-conditions">condition</a>
is added to indicate
that the Pod is about to be deleted due to a <a class="glossary-tooltip" title="An event that leads to Pod(s) going out of service" data-toggle="tooltip" data-placement="top" href="/docs/concepts/workloads/pods/disruptions/" target="_blank" aria-label="disruption">disruption</a>.
The <code>reason</code> field of the condition additionally
indicates one of the following reasons for the Pod termination:</p><dl><dt><code>PreemptionByScheduler</code></dt><dd>Pod is due to be <a class="glossary-tooltip" title="Preemption logic in Kubernetes helps a pending Pod to find a suitable Node by evicting low priority Pods existing on that Node." data-toggle="tooltip" data-placement="top" href="/docs/concepts/scheduling-eviction/pod-priority-preemption/#preemption" target="_blank" aria-label="preempted">preempted</a> by a scheduler in order to accommodate a new Pod with a higher priority. For more information, see <a href="/docs/concepts/scheduling-eviction/pod-priority-preemption/">Pod priority preemption</a>.</dd><dt><code>DeletionByTaintManager</code></dt><dd>Pod is due to be deleted by Taint Manager (which is part of the node lifecycle controller within <code>kube-controller-manager</code>) due to a <code>NoExecute</code> taint that the Pod does not tolerate; see <a class="glossary-tooltip" title="A core object consisting of three required properties: key, value, and effect. Taints prevent the scheduling of pods on nodes or node groups." data-toggle="tooltip" data-placement="top" href="/docs/concepts/scheduling-eviction/taint-and-toleration/" target="_blank" aria-label="taint">taint</a>-based evictions.</dd><dt><code>EvictionByEvictionAPI</code></dt><dd>Pod has been marked for <a class="glossary-tooltip" title="API-initiated eviction is the process by which you use the Eviction API to create an Eviction object that triggers graceful pod termination." data-toggle="tooltip" data-placement="top" href="/docs/concepts/scheduling-eviction/api-eviction/" target="_blank" aria-label="eviction using the Kubernetes API">eviction using the Kubernetes API</a> .</dd><dt><code>DeletionByPodGC</code></dt><dd>Pod, that is bound to a no longer existing Node, is due to be deleted by <a href="/docs/concepts/workloads/pods/pod-lifecycle/#pod-garbage-collection">Pod garbage collection</a>.</dd><dt><code>TerminationByKubelet</code></dt><dd>Pod has been terminated by the kubelet, because of either <a class="glossary-tooltip" title="Node-pressure eviction is the process by which the kubelet proactively fails pods to reclaim resources on nodes." data-toggle="tooltip" data-placement="top" href="/docs/concepts/scheduling-eviction/node-pressure-eviction/" target="_blank" aria-label="node pressure eviction">node pressure eviction</a>,
the <a href="/docs/concepts/architecture/nodes/#graceful-node-shutdown">graceful node shutdown</a>,
or preemption for <a href="/docs/tasks/administer-cluster/guaranteed-scheduling-critical-addon-pods/">system critical pods</a>.</dd></dl><p>In all other disruption scenarios, like eviction due to exceeding
<a href="/docs/concepts/configuration/manage-resources-containers/">Pod container limits</a>,
Pods don't receive the <code>DisruptionTarget</code> condition because the disruptions were
probably caused by the Pod and would reoccur on retry.</p><div class="alert alert-info" role="alert"><h4 class="alert-heading">Note:</h4>A Pod disruption might be interrupted. The control plane might re-attempt to
continue the disruption of the same Pod, but it is not guaranteed. As a result,
the <code>DisruptionTarget</code> condition might be added to a Pod, but that Pod might then not actually be
deleted. In such a situation, after some time, the
Pod disruption condition will be cleared.</div><p>Along with cleaning up the pods, the Pod garbage collector (PodGC) will also mark them as failed if they are in a non-terminal
phase (see also <a href="/docs/concepts/workloads/pods/pod-lifecycle/#pod-garbage-collection">Pod garbage collection</a>).</p><p>When using a Job (or CronJob), you may want to use these Pod disruption conditions as part of your Job's
<a href="/docs/concepts/workloads/controllers/job/#pod-failure-policy">Pod failure policy</a>.</p><h2 id="separating-cluster-owner-and-application-owner-roles">Separating Cluster Owner and Application Owner Roles</h2><p>Often, it is useful to think of the Cluster Manager
and Application Owner as separate roles with limited knowledge
of each other. This separation of responsibilities
may make sense in these scenarios:</p><ul><li>when there are many application teams sharing a Kubernetes cluster, and
there is natural specialization of roles</li><li>when third-party tools or services are used to automate cluster management</li></ul><p>Pod Disruption Budgets support this separation of roles by providing an
interface between the roles.</p><p>If you do not have such a separation of responsibilities in your organization,
you may not need to use Pod Disruption Budgets.</p><h2 id="how-to-perform-disruptive-actions-on-your-cluster">How to perform Disruptive Actions on your Cluster</h2><p>If you are a Cluster Administrator, and you need to perform a disruptive action on all
the nodes in your cluster, such as a node or system software upgrade, here are some options:</p><ul><li>Accept downtime during the upgrade.</li><li>Failover to another complete replica cluster.<ul><li>No downtime, but may be costly both for the duplicated nodes
and for human effort to orchestrate the switchover.</li></ul></li><li>Write disruption tolerant applications and use PDBs.<ul><li>No downtime.</li><li>Minimal resource duplication.</li><li>Allows more automation of cluster administration.</li><li>Writing disruption-tolerant applications is tricky, but the work to tolerate voluntary
disruptions largely overlaps with work to support autoscaling and tolerating
involuntary disruptions.</li></ul></li></ul><h2 id="what-s-next">What's next</h2><ul><li><p>Follow steps to protect your application by <a href="/docs/tasks/run-application/configure-pdb/">configuring a Pod Disruption Budget</a>.</p></li><li><p>Learn more about <a href="/docs/tasks/administer-cluster/safely-drain-node/">draining nodes</a></p></li><li><p>Learn about <a href="/docs/concepts/workloads/controllers/deployment/#updating-a-deployment">updating a deployment</a>
including steps to maintain its availability during the rollout.</p></li></ul></div>