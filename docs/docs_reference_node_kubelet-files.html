<div class="td-content"><h1 data-pagefind-weight="10">Local Files And Paths Used By The Kubelet</h1><p>The <a class="glossary-tooltip" title="An agent that runs on each node in the cluster. It makes sure that containers are running in a pod." data-toggle="tooltip" data-placement="top" href="/docs/reference/command-line-tools-reference/kubelet" target="_blank" aria-label="kubelet">kubelet</a> is mostly a stateless
process running on a Kubernetes <a class="glossary-tooltip" title="A node is a worker machine in Kubernetes." data-toggle="tooltip" data-placement="top" href="/docs/concepts/architecture/nodes/" target="_blank" aria-label="node">node</a>.
This document outlines files that kubelet reads and writes.</p><div class="alert alert-info" role="alert"><h4 class="alert-heading">Note:</h4>This document is for informational purpose and not describing any guaranteed behaviors or APIs.
It lists resources used by the kubelet, which is an implementation detail and a subject to change at any release.</div><p>The kubelet typically uses the <a class="glossary-tooltip" title="The container orchestration layer that exposes the API and interfaces to define, deploy, and manage the lifecycle of containers." data-toggle="tooltip" data-placement="top" href="/docs/reference/glossary/?all=true#term-control-plane" target="_blank" aria-label="control plane">control plane</a> as
the source of truth on what needs to run on the Node, and the
<a class="glossary-tooltip" title="The container runtime is the software that is responsible for running containers." data-toggle="tooltip" data-placement="top" href="/docs/setup/production-environment/container-runtimes" target="_blank" aria-label="container runtime">container runtime</a> to retrieve
the current state of containers. So long as you provide a <em>kubeconfig</em> (API client configuration)
to the kubelet, the kubelet does connect to your control plane; otherwise the node operates in
<em>standalone mode</em>.</p><p>On Linux nodes, the kubelet also relies on reading cgroups and various system files to collect metrics.</p><p>On Windows nodes, the kubelet collects metrics via a different mechanism that does not rely on
paths.</p><p>There are also a few other files that are used by the kubelet as well,
as kubelet communicates using local Unix-domain sockets. Some are sockets that the
kubelet listens on, and for other sockets the kubelet discovers them and then connects
as a client.</p><div class="alert alert-info" role="alert"><h4 class="alert-heading">Note:</h4>This page lists paths as Linux paths, which map to the Windows paths by adding a root disk
<code>C:\</code> in place of <code>/</code> (unless specified otherwise).
For example, <code>/var/lib/kubelet/device-plugins</code> maps to <code>C:\var\lib\kubelet\device-plugins</code>.</div><h2 id="configuration">Configuration</h2><h3 id="kubelet-configuration-files">Kubelet configuration files</h3><p>The path to the kubelet configuration file can be configured
using the command line argument <code>--config</code>. The kubelet also supports
<a href="/docs/tasks/administer-cluster/kubelet-config-file/#kubelet-conf-d">drop-in configuration files</a>
to enhance configuration.</p><h3 id="certificates">Certificates</h3><p>Certificates and private keys are typically located at <code>/var/lib/kubelet/pki</code>,
but can be configured using the <code>--cert-dir</code> kubelet command line argument.
Names of certificate files are also configurable.</p><h3 id="manifests">Manifests</h3><p>Manifests for static pods are typically located in <code>/etc/kubernetes/manifests</code>.
Location can be configured using the <code>staticPodPath</code> kubelet configuration option.</p><h3 id="systemd-unit-settings">Systemd unit settings</h3><p>When kubelet is running as a systemd unit, some kubelet configuration may be declared
in systemd unit settings file. Typically it includes:</p><ul><li>command line arguments to <a href="/docs/reference/command-line-tools-reference/kubelet/">run kubelet</a></li><li>environment variables, used by kubelet or <a href="https://pkg.go.dev/runtime#hdr-Environment_Variables">configuring golang runtime</a></li></ul><h2 id="state">State</h2><h3 id="resource-managers-state">Checkpoint files for resource managers</h3><p>All resource managers keep the mapping of Pods to allocated resources in state files.
State files are located in the kubelet's base directory, also termed the <em>root directory</em>
(but not the same as <code>/</code>, the node root directory). You can configure the base directory
for the kubelet
using the kubelet command line argument <code>--root-dir</code>.</p><p>Names of files:</p><ul><li><code>memory_manager_state</code> for the <a href="/docs/tasks/administer-cluster/memory-manager/">Memory Manager</a></li><li><code>cpu_manager_state</code> for the <a href="/docs/tasks/administer-cluster/cpu-management-policies/">CPU Manager</a></li><li><code>dra_manager_state</code> for <a href="/docs/concepts/scheduling-eviction/dynamic-resource-allocation/">DRA</a></li></ul><h3 id="device-manager-state">Checkpoint file for device manager</h3><p>Device manager creates checkpoints in the same directory with socket files: <code>/var/lib/kubelet/device-plugins/</code>.
The name of a checkpoint file is <code>kubelet_internal_checkpoint</code> for
<a href="/docs/concepts/extend-kubernetes/compute-storage-net/device-plugins/#device-plugin-integration-with-the-topology-manager">Device Manager</a></p><h3 id="pod-resource-checkpoints">Pod resource checkpoints</h3><div class="feature-state-notice feature-beta" title="Feature Gate: InPlacePodVerticalScaling"><span class="feature-state-name">FEATURE STATE:</span>
<code>Kubernetes v1.33 [beta]</code> (enabled by default: true)</div><p>If a node has enabled the <code>InPlacePodVerticalScaling</code><a href="/docs/reference/command-line-tools-reference/feature-gates/">feature gate</a>,
the kubelet stores a local record of <em>allocated</em> and <em>actuated</em> Pod resources.
See <a href="/docs/tasks/configure-pod-container/resize-container-resources/">Resize CPU and Memory Resources assigned to Containers</a>
for more details on how these records are used.</p><p>Names of files:</p><ul><li><code>allocated_pods_state</code> records the resources allocated to each pod running on the node</li><li><code>actuated_pods_state</code> records the resources that have been accepted by the runtime
for each pod pod running on the node</li></ul><p>The files are located within the kubelet base directory
(<code>/var/lib/kubelet</code> by default on Linux; configurable using <code>--root-dir</code>).</p><h3 id="container-runtime">Container runtime</h3><p>Kubelet communicates with the container runtime using socket configured via the
configuration parameters:</p><ul><li><code>containerRuntimeEndpoint</code> for runtime operations</li><li><code>imageServiceEndpoint</code> for image management operations</li></ul><p>The actual values of those endpoints depend on the container runtime being used.</p><h3 id="device-plugins">Device plugins</h3><p>The kubelet exposes a socket at the path <code>/var/lib/kubelet/device-plugins/kubelet.sock</code> for
various <a href="/docs/concepts/extend-kubernetes/compute-storage-net/device-plugins/#device-plugin-implementation">Device Plugins to register</a>.</p><p>When a device plugin registers itself, it provides its socket path for the kubelet to connect.</p><p>The device plugin socket should be in the directory <code>device-plugins</code> within the kubelet base
directory. On a typical Linux node, this means <code>/var/lib/kubelet/device-plugins</code>.</p><h3 id="pod-resources-api">Pod resources API</h3><p><a href="/docs/concepts/extend-kubernetes/compute-storage-net/device-plugins/#monitoring-device-plugin-resources">Pod Resources API</a>
will be exposed at the path <code>/var/lib/kubelet/pod-resources</code>.</p><h3 id="dra-csi-and-device-plugins">DRA, CSI, and Device plugins</h3><p>The kubelet looks for socket files created by device plugins managed via <a href="/docs/concepts/scheduling-eviction/dynamic-resource-allocation/">DRA</a>,
device manager, or storage plugins, and then attempts to connect
to these sockets. The directory that the kubelet looks in is <code>plugins_registry</code> within the kubelet base
directory, so on a typical Linux node this means <code>/var/lib/kubelet/plugins_registry</code>.</p><p>Note, for the device plugins there are two alternative registration mechanisms
Only one should be used for a given plugin.</p><p>The types of plugins that can place socket files into that directory are:</p><ul><li>CSI plugins</li><li>DRA plugins</li><li>Device Manager plugins</li></ul><p>(typically <code>/var/lib/kubelet/plugins_registry</code>).</p><h3 id="graceful-node-shutdown">Graceful node shutdown</h3><div class="feature-state-notice feature-beta" title="Feature Gate: GracefulNodeShutdown"><span class="feature-state-name">FEATURE STATE:</span>
<code>Kubernetes v1.21 [beta]</code> (enabled by default: true)</div><p><a href="/docs/concepts/cluster-administration/node-shutdown/#graceful-node-shutdown">Graceful node shutdown</a>
stores state locally at <code>/var/lib/kubelet/graceful_node_shutdown_state</code>.</p><h3 id="image-pull-records">Image Pull Records</h3><div class="feature-state-notice feature-alpha" title="Feature Gate: KubeletEnsureSecretPulledImages"><span class="feature-state-name">FEATURE STATE:</span>
<code>Kubernetes v1.33 [alpha]</code> (enabled by default: false)</div><p>The kubelet stores records of attempted and successful image pulls, and uses it
to verify that the image was previously successfully pulled with the same credentials.</p><p>These records are cached as files in the <code>image_registry</code> directory within
the kubelet base directory. On a typical Linux node, this means <code>/var/lib/kubelet/image_manager</code>.
There are two subdirectories to <code>image_manager</code>:</p><ul><li><code>pulling</code> - stores records about images the Kubelet is attempting to pull.</li><li><code>pulled</code> - stores records about images that were successfully pulled by the Kubelet,
along with metadata about the credentials used for the pulls.</li></ul><p>See <a href="/docs/concepts/containers/images/#ensureimagepullcredentialverification">Ensure Image Pull Credential Verification</a>
for details.</p><h2 id="security-profiles-configuration">Security profiles &amp; configuration</h2><h3 id="seccomp">Seccomp</h3><p>Seccomp profile files referenced from Pods should be placed in <code>/var/lib/kubelet/seccomp</code>.
See the <a href="/docs/reference/node/seccomp/">seccomp reference</a> for details.</p><h3 id="apparmor">AppArmor</h3><p>The kubelet does not load or refer to AppArmor profiles by a Kubernetes-specific path.
AppArmor profiles are loaded via the node operating system rather then referenced by their path.</p><h2 id="locking">Locking</h2><div class="feature-state-notice feature-alpha"><span class="feature-state-name">FEATURE STATE:</span>
<code>Kubernetes v1.2 [alpha]</code></div><p>A lock file for the kubelet; typically <code>/var/run/kubelet.lock</code>. The kubelet uses this to ensure
that two different kubelets don't try to run in conflict with each other.
You can configure the path to the lock file using the the <code>--lock-file</code> kubelet command line argument.</p><p>If two kubelets on the same node use a different value for the lock file path, they will not be able to
detect a conflict when both are running.</p><h2 id="what-s-next">What's next</h2><ul><li>Learn about the kubelet <a href="/docs/reference/command-line-tools-reference/kubelet/">command line arguments</a>.</li><li>Review the <a href="/docs/reference/config-api/kubelet-config.v1beta1/">Kubelet Configuration (v1beta1) reference</a></li></ul></div>