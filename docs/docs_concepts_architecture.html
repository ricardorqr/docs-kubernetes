<div class="td-content"><h1 data-pagefind-weight="10">Cluster Architecture</h1><div class="lead">The architectural concepts behind Kubernetes.</div><p>A Kubernetes cluster consists of a control plane plus a set of worker machines, called nodes,
that run containerized applications. Every cluster needs at least one worker node in order to run Pods.</p><p>The worker node(s) host the Pods that are the components of the application workload.
The control plane manages the worker nodes and the Pods in the cluster. In production
environments, the control plane usually runs across multiple computers and a cluster
usually runs multiple nodes, providing fault-tolerance and high availability.</p><p>This document outlines the various components you need to have for a complete and working Kubernetes cluster.</p><figure class="diagram-large"><img src="/images/docs/kubernetes-cluster-architecture.svg" alt="The control plane (kube-apiserver, etcd, kube-controller-manager, kube-scheduler) and several nodes. Each node is running a kubelet and kube-proxy."/><figcaption><p>Figure 1. Kubernetes cluster components.</p></figcaption></figure><details><summary>About this architecture</summary><div class="details-inner"><p>The diagram in Figure 1 presents an example reference architecture for a Kubernetes cluster.
The actual distribution of components can vary based on specific cluster setups and requirements.</p><p>In the diagram, each node runs the <a href="#kube-proxy"><code>kube-proxy</code></a> component. You need a
network proxy component on each node to ensure that the
<a class="glossary-tooltip" title="A way to expose an application running on a set of Pods as a network service." data-toggle="tooltip" data-placement="top" href="/docs/concepts/services-networking/service/" target="_blank" aria-label="Service">Service</a> API and associated behaviors
are available on your cluster network. However, some network plugins provide their own,
third party implementation of proxying. When you use that kind of network plugin,
the node does not need to run <code>kube-proxy</code>.</p></div></details><h2 id="control-plane-components">Control plane components</h2><p>The control plane's components make global decisions about the cluster (for example, scheduling),
as well as detecting and responding to cluster events (for example, starting up a new
<a class="glossary-tooltip" title="A Pod represents a set of running containers in your cluster." data-toggle="tooltip" data-placement="top" href="/docs/concepts/workloads/pods/" target="_blank" aria-label="pod">pod</a> when a Deployment's
<code><a class="glossary-tooltip" title="Replicas are copies of pods, ensuring availability, scalability, and fault tolerance by maintaining identical instances." data-toggle="tooltip" data-placement="top" href="/docs/reference/glossary/?all=true#term-replica" target="_blank" aria-label="replicas">replicas</a></code> field is unsatisfied).</p><p>Control plane components can be run on any machine in the cluster. However, for simplicity, setup scripts
typically start all control plane components on the same machine, and do not run user containers on this machine.
See <a href="/docs/setup/production-environment/tools/kubeadm/high-availability/">Creating Highly Available clusters with kubeadm</a>
for an example control plane setup that runs across multiple machines.</p><h3 id="kube-apiserver">kube-apiserver</h3><p>The API server is a component of the Kubernetes
<a class="glossary-tooltip" title="The container orchestration layer that exposes the API and interfaces to define, deploy, and manage the lifecycle of containers." data-toggle="tooltip" data-placement="top" href="/docs/reference/glossary/?all=true#term-control-plane" target="_blank" aria-label="control plane">control plane</a> that exposes the Kubernetes API.
The API server is the front end for the Kubernetes control plane.</p><p>The main implementation of a Kubernetes API server is <a href="/docs/reference/generated/kube-apiserver/">kube-apiserver</a>.
kube-apiserver is designed to scale horizontallyâ€”that is, it scales by deploying more instances.
You can run several instances of kube-apiserver and balance traffic between those instances.</p><h3 id="etcd">etcd</h3><p>Consistent and highly-available key value store used as Kubernetes' backing store for all cluster data.</p><p>If your Kubernetes cluster uses etcd as its backing store, make sure you have a
<a href="/docs/tasks/administer-cluster/configure-upgrade-etcd/#backing-up-an-etcd-cluster">back up</a> plan
for the data.</p><p>You can find in-depth information about etcd in the official <a href="https://etcd.io/docs/">documentation</a>.</p><h3 id="kube-scheduler">kube-scheduler</h3><p>Control plane component that watches for newly created
<a class="glossary-tooltip" title="A Pod represents a set of running containers in your cluster." data-toggle="tooltip" data-placement="top" href="/docs/concepts/workloads/pods/" target="_blank" aria-label="Pods">Pods</a> with no assigned
<a class="glossary-tooltip" title="A node is a worker machine in Kubernetes." data-toggle="tooltip" data-placement="top" href="/docs/concepts/architecture/nodes/" target="_blank" aria-label="node">node</a>, and selects a node for them
to run on.</p><p>Factors taken into account for scheduling decisions include:
individual and collective <a class="glossary-tooltip" title="A defined amount of infrastructure available for consumption (CPU, memory, etc)." data-toggle="tooltip" data-placement="top" href="/docs/reference/glossary/?all=true#term-infrastructure-resource" target="_blank" aria-label="resource">resource</a>
requirements, hardware/software/policy constraints, affinity and anti-affinity specifications,
data locality, inter-workload interference, and deadlines.</p><h3 id="kube-controller-manager">kube-controller-manager</h3><p>Control plane component that runs <a class="glossary-tooltip" title="A control loop that watches the shared state of the cluster through the apiserver and makes changes attempting to move the current state towards the desired state." data-toggle="tooltip" data-placement="top" href="/docs/concepts/architecture/controller/" target="_blank" aria-label="controller">controller</a> processes.</p><p>Logically, each <a class="glossary-tooltip" title="A control loop that watches the shared state of the cluster through the apiserver and makes changes attempting to move the current state towards the desired state." data-toggle="tooltip" data-placement="top" href="/docs/concepts/architecture/controller/" target="_blank" aria-label="controller">controller</a> is a separate process, but to reduce complexity, they are all compiled into a single binary and run in a single process.</p><p>There are many different types of controllers. Some examples of them are:</p><ul><li>Node controller: Responsible for noticing and responding when nodes go down.</li><li>Job controller: Watches for Job objects that represent one-off tasks, then creates Pods to run those tasks to completion.</li><li>EndpointSlice controller: Populates EndpointSlice objects (to provide a link between Services and Pods).</li><li>ServiceAccount controller: Create default ServiceAccounts for new namespaces.</li></ul><p>The above is not an exhaustive list.</p><h3 id="cloud-controller-manager">cloud-controller-manager</h3>A Kubernetes <a class="glossary-tooltip" title="The container orchestration layer that exposes the API and interfaces to define, deploy, and manage the lifecycle of containers." data-toggle="tooltip" data-placement="top" href="/docs/reference/glossary/?all=true#term-control-plane" target="_blank" aria-label="control plane">control plane</a> component
that embeds cloud-specific control logic. The cloud controller manager lets you link your
cluster into your cloud provider's API, and separates out the components that interact
with that cloud platform from components that only interact with your cluster.<p>The cloud-controller-manager only runs controllers that are specific to your cloud provider.
If you are running Kubernetes on your own premises, or in a learning environment inside your
own PC, the cluster does not have a cloud controller manager.</p><p>As with the kube-controller-manager, the cloud-controller-manager combines several logically
independent control loops into a single binary that you run as a single process. You can scale
horizontally (run more than one copy) to improve performance or to help tolerate failures.</p><p>The following controllers can have cloud provider dependencies:</p><ul><li>Node controller: For checking the cloud provider to determine if a node has been
deleted in the cloud after it stops responding</li><li>Route controller: For setting up routes in the underlying cloud infrastructure</li><li>Service controller: For creating, updating and deleting cloud provider load balancers</li></ul><hr/><h2 id="node-components">Node components</h2><p>Node components run on every node, maintaining running pods and providing the Kubernetes runtime environment.</p><h3 id="kubelet">kubelet</h3><p>An agent that runs on each <a class="glossary-tooltip" title="A node is a worker machine in Kubernetes." data-toggle="tooltip" data-placement="top" href="/docs/concepts/architecture/nodes/" target="_blank" aria-label="node">node</a> in the cluster. It makes sure that <a class="glossary-tooltip" title="A lightweight and portable executable image that contains software and all of its dependencies." data-toggle="tooltip" data-placement="top" href="/docs/concepts/containers/" target="_blank" aria-label="containers">containers</a> are running in a <a class="glossary-tooltip" title="A Pod represents a set of running containers in your cluster." data-toggle="tooltip" data-placement="top" href="/docs/concepts/workloads/pods/" target="_blank" aria-label="Pod">Pod</a>.</p><p>The <a href="/docs/reference/command-line-tools-reference/kubelet/">kubelet</a> takes a set of PodSpecs that
are provided through various mechanisms and ensures that the containers described in those
PodSpecs are running and healthy. The kubelet doesn't manage containers which were not created by
Kubernetes.</p><h3 id="kube-proxy">kube-proxy (optional)</h3><p><p>kube-proxy is a network proxy that runs on each
<a class="glossary-tooltip" title="A node is a worker machine in Kubernetes." data-toggle="tooltip" data-placement="top" href="/docs/concepts/architecture/nodes/" target="_blank" aria-label="node">node</a> in your cluster,
implementing part of the Kubernetes
<a class="glossary-tooltip" title="A way to expose an application running on a set of Pods as a network service." data-toggle="tooltip" data-placement="top" href="/docs/concepts/services-networking/service/" target="_blank" aria-label="Service">Service</a> concept.</p><p><a href="/docs/reference/command-line-tools-reference/kube-proxy/">kube-proxy</a>
maintains network rules on nodes. These network rules allow network
communication to your Pods from network sessions inside or outside of
your cluster.</p><p>kube-proxy uses the operating system packet filtering layer if there is one
and it's available. Otherwise, kube-proxy forwards the traffic itself.</p>If you use a <a href="#network-plugins">network plugin</a> that implements packet forwarding for Services
by itself, and providing equivalent behavior to kube-proxy, then you do not need to run
kube-proxy on the nodes in your cluster.</p><h3 id="container-runtime">Container runtime</h3><p>A fundamental component that empowers Kubernetes to run containers effectively.
It is responsible for managing the execution and lifecycle of containers within the Kubernetes environment.</p><p>Kubernetes supports container runtimes such as
<a class="glossary-tooltip" title="A container runtime with an emphasis on simplicity, robustness and portability" data-toggle="tooltip" data-placement="top" href="https://containerd.io/docs/" target="_blank" aria-label="containerd">containerd</a>, <a class="glossary-tooltip" title="A lightweight container runtime specifically for Kubernetes" data-toggle="tooltip" data-placement="top" href="https://cri-o.io/#what-is-cri-o" target="_blank" aria-label="CRI-O">CRI-O</a>,
and any other implementation of the <a href="https://github.com/kubernetes/community/blob/master/contributors/devel/sig-node/container-runtime-interface.md">Kubernetes CRI (Container Runtime
Interface)</a>.</p><h2 id="addons">Addons</h2><p>Addons use Kubernetes resources (<a class="glossary-tooltip" title="Ensures a copy of a Pod is running across a set of nodes in a cluster." data-toggle="tooltip" data-placement="top" href="/docs/concepts/workloads/controllers/daemonset" target="_blank" aria-label="DaemonSet">DaemonSet</a>,
<a class="glossary-tooltip" title="Manages a replicated application on your cluster." data-toggle="tooltip" data-placement="top" href="/docs/concepts/workloads/controllers/deployment/" target="_blank" aria-label="Deployment">Deployment</a>, etc) to implement cluster features.
Because these are providing cluster-level features, namespaced resources for
addons belong within the <code>kube-system</code> namespace.</p><p>Selected addons are described below; for an extended list of available addons,
please see <a href="/docs/concepts/cluster-administration/addons/">Addons</a>.</p><h3 id="dns">DNS</h3><p>While the other addons are not strictly required, all Kubernetes clusters should have
<a href="/docs/concepts/services-networking/dns-pod-service/">cluster DNS</a>, as many examples rely on it.</p><p>Cluster DNS is a DNS server, in addition to the other DNS server(s) in your environment,
which serves DNS records for Kubernetes services.</p><p>Containers started by Kubernetes automatically include this DNS server in their DNS searches.</p><h3 id="web-ui-dashboard">Web UI (Dashboard)</h3><p><a href="/docs/tasks/access-application-cluster/web-ui-dashboard/">Dashboard</a> is a general purpose,
web-based UI for Kubernetes clusters. It allows users to manage and troubleshoot applications
running in the cluster, as well as the cluster itself.</p><h3 id="container-resource-monitoring">Container resource monitoring</h3><p><a href="/docs/tasks/debug/debug-cluster/resource-usage-monitoring/">Container Resource Monitoring</a>
records generic time-series metrics about containers in a central database, and provides a UI for browsing that data.</p><h3 id="cluster-level-logging">Cluster-level Logging</h3><p>A <a href="/docs/concepts/cluster-administration/logging/">cluster-level logging</a> mechanism is responsible
for saving container logs to a central log store with a search/browsing interface.</p><h3 id="network-plugins">Network plugins</h3><p><a href="/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/">Network plugins</a>
are software components that implement the container network interface (CNI) specification.
They are responsible for allocating IP addresses to pods and enabling them to communicate
with each other within the cluster.</p><h2 id="architecture-variations">Architecture variations</h2><p>While the core components of Kubernetes remain consistent, the way they are deployed and
managed can vary. Understanding these variations is crucial for designing and maintaining
Kubernetes clusters that meet specific operational needs.</p><h3 id="control-plane-deployment-options">Control plane deployment options</h3><p>The control plane components can be deployed in several ways:</p><dl><dt>Traditional deployment</dt><dd>Control plane components run directly on dedicated machines or VMs, often managed as systemd services.</dd><dt>Static Pods</dt><dd>Control plane components are deployed as static Pods, managed by the kubelet on specific nodes.
This is a common approach used by tools like kubeadm.</dd><dt>Self-hosted</dt><dd>The control plane runs as Pods within the Kubernetes cluster itself, managed by Deployments
and StatefulSets or other Kubernetes primitives.</dd><dt>Managed Kubernetes services</dt><dd>Cloud providers often abstract away the control plane, managing its components as part of their service offering.</dd></dl><h3 id="workload-placement-considerations">Workload placement considerations</h3><p>The placement of workloads, including the control plane components, can vary based on cluster size,
performance requirements, and operational policies:</p><ul><li>In smaller or development clusters, control plane components and user workloads might run on the same nodes.</li><li>Larger production clusters often dedicate specific nodes to control plane components,
separating them from user workloads.</li><li>Some organizations run critical add-ons or monitoring tools on control plane nodes.</li></ul><h3 id="cluster-management-tools">Cluster management tools</h3><p>Tools like kubeadm, kops, and Kubespray offer different approaches to deploying and managing clusters,
each with its own method of component layout and management.</p><p>The flexibility of Kubernetes architecture allows organizations to tailor their clusters to specific needs,
balancing factors such as operational complexity, performance, and management overhead.</p><h3 id="customization-and-extensibility">Customization and extensibility</h3><p>Kubernetes architecture allows for significant customization:</p><ul><li>Custom schedulers can be deployed to work alongside the default Kubernetes scheduler or to replace it entirely.</li><li>API servers can be extended with CustomResourceDefinitions and API Aggregation.</li><li>Cloud providers can integrate deeply with Kubernetes using the cloud-controller-manager.</li></ul><p>The flexibility of Kubernetes architecture allows organizations to tailor their clusters to specific needs,
balancing factors such as operational complexity, performance, and management overhead.</p><h2 id="what-s-next">What's next</h2><p>Learn more about the following:</p><ul><li><a href="/docs/concepts/architecture/nodes/">Nodes</a> and
<a href="/docs/concepts/architecture/control-plane-node-communication/">their communication</a>
with the control plane.</li><li>Kubernetes <a href="/docs/concepts/architecture/controller/">controllers</a>.</li><li><a href="/docs/concepts/scheduling-eviction/kube-scheduler/">kube-scheduler</a> which is the default scheduler for Kubernetes.</li><li>Etcd's official <a href="https://etcd.io/docs/">documentation</a>.</li><li>Several <a href="/docs/setup/production-environment/container-runtimes/">container runtimes</a> in Kubernetes.</li><li>Integrating with cloud providers using <a href="/docs/concepts/architecture/cloud-controller/">cloud-controller-manager</a>.</li><li><a href="/docs/reference/generated/kubectl/kubectl-commands">kubectl</a> commands.</li></ul><div class="section-index"><hr class="panel-line"/><div class="entry"><h5><a href="/docs/concepts/architecture/nodes/">Nodes</a></h5><p/></div><div class="entry"><h5><a href="/docs/concepts/architecture/control-plane-node-communication/">Communication between Nodes and the Control Plane</a></h5><p/></div><div class="entry"><h5><a href="/docs/concepts/architecture/controller/">Controllers</a></h5><p/></div><div class="entry"><h5><a href="/docs/concepts/architecture/leases/">Leases</a></h5><p/></div><div class="entry"><h5><a href="/docs/concepts/architecture/cloud-controller/">Cloud Controller Manager</a></h5><p/></div><div class="entry"><h5><a href="/docs/concepts/architecture/cgroups/">About cgroup v2</a></h5><p/></div><div class="entry"><h5><a href="/docs/concepts/architecture/self-healing/">Kubernetes Self-Healing</a></h5><p/></div><div class="entry"><h5><a href="/docs/concepts/architecture/garbage-collection/">Garbage Collection</a></h5><p/></div><div class="entry"><h5><a href="/docs/concepts/architecture/mixed-version-proxy/">Mixed Version Proxy</a></h5><p/></div></div></div>